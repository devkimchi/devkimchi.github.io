<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>DevKimchi</title>
  <subtitle>Fermentation: Turning MS Tech Stack, .NET and Web into Something</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://devkimchi.com/"/>
  <updated>2016-09-13T12:11:48.473Z</updated>
  <id>http://devkimchi.com/</id>
  
  <author>
    <name>DevKimchi</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>How to use bower to manage front-end library in Visual Studio 2015 : for beginners</title>
    <link href="http://devkimchi.com/2016/07/20/how-to-use-bower-to-manage-front-end-library-in-visual-studio-2015-for-beginners/"/>
    <id>http://devkimchi.com/2016/07/20/how-to-use-bower-to-manage-front-end-library-in-visual-studio-2015-for-beginners/</id>
    <published>2016-07-20T12:02:03.000Z</published>
    <updated>2016-09-13T12:11:48.473Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>While looking for the JS libary to populate folder as beautiful tree structure and hopefully having modern UI, I found a useful angularjs based open source called, angular file manager(<a href="https://github.com/joni2back/angular-filemanager" target="_blank" rel="external">git</a>), which has beautiful and easy-to-use UI, worth to spend some time for my work.</p>
<p>The manual of the app said ‘use <em>bower install –save angular-filemanager’</em> to use in existing app. It sounded very easy, because it looks to me that that magic word looks doing all heavy lifting. However, I didn’t know how to use bower in my ASP.Net MVC 5 app within Visual Studio 2015.</p>
<p>Searching a bit for how to use bower in Visual Studio 2015, I found bunch of great articles and blogs, but most of explanation and tutorial wasn’t that straightforward.</p>
<p>So, I just write down my way to keep record of it. In VS 2015 it should be easier than what it used to be in VS 2013.</p>
<h2 id="Challenge"><a href="#Challenge" class="headerlink" title="Challenge"></a>Challenge</h2><p>The first challenge was so many new tools involved. e.g. Node.js, npm, bower, gulp, grunt.</p>
<p>To have a taste of Node.js, <a href="https://johnpapa.net/get-up-and-running-with-node-and-visual-studio/" target="_blank" rel="external">https://johnpapa.net/get-up-and-running-with-node-and-visual-studio/</a> is well written by John Papa.</p>
<p>If you still using VS 2013, <a href="http://devkimchi.com/1511/integrating-grunt-and-bower-with-visual-studio-2013/">http://devkimchi.com/1511/integrating-grunt-and-bower-with-visual-studio-2013/</a> will be great place to refer.</p>
<p>I found that <a href="https://chsakell.com/2015/09/19/typescript-angularjs-gulp-and-bower-in-visual-studio-2015/" target="_blank" rel="external">https://chsakell.com/2015/09/19/typescript-angularjs-gulp-and-bower-in-visual-studio-2015/</a> is the best to understand 101 around these package manager.</p>
<p>For beginner like me, there were quite a few information to digest. So, let’s do this in an easiest way. After some reading, I decided to use bower to manage all front-end JS libaries and CSS libaries. I’ll use nuget only for .Net libraries. Reason for this decision is that 1) more and more front-end libraries and open-sources will be shared though bower 2) the way bower keep the dependency is simpler than nuget, which sometimes does not work clean as it ideally should do.</p>
<h2 id="How-I-did"><a href="#How-I-did" class="headerlink" title="How I did"></a>How I did</h2><p>I created basic APS.Net MVC project which includes jquery and bootstrap as a default. I will replace those jquery and bootstrap in Scripts folder with ones managed by bower.</p>
<p>&nbsp;</p>
<p><strong>1. NPM</strong></p>
<p>To start with, we need npm, bower and gulp. VS2015 comes with Node.js and Bower. So, just make sure we have both in Command Prompt.</p>
<div class="code-embed-wrapper"><br><br>    npm <span class="token operator">-</span>v`<br>    <div class="code-embed-infos"></div><br>    </div>

<pre><code>If npm is installed, you will see the version number. If not, go to Node.js home page and install it.

&amp;nbsp;

**2\. Bower**

Check if bower has been installed already.

&lt;div class=&quot;code-embed-wrapper&quot;&gt;
&lt;pre class=&quot; code-embed-pre language-markup&quot;&gt;`bower -v`&lt;/pre&gt;
&lt;div class=&quot;code-embed-infos&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

If not, install it as global, using npm.

&lt;div class=&quot;code-embed-wrapper&quot;&gt;
&lt;pre class=&quot; code-embed-pre language-markup&quot;&gt;`npm install -g bower`&lt;/pre&gt;
&lt;div class=&quot;code-embed-infos&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&amp;nbsp;

**3\. Gulp**

Install gulp.

&lt;div class=&quot;code-embed-wrapper&quot;&gt;
&lt;pre class=&quot; code-embed-pre language-markup&quot;&gt;`npm install -g gulp
</code></pre><div class="code-embed-infos"></div><br>

<p>&nbsp;</p>
<p><strong>4. Configure bower</strong></p>
<p>Once created a default ASP.Net MVC web app, we can see jquery and other JS libaries are automatically installed in Scripts folder using Nuget.</p>
<p><a href="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower2.jpg" target="_blank" rel="external"><img src="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower2.jpg" alt="bower2"></a></p>
<p>So, uninstall jquery, jquery.validate, bootstrap using NuGet.</p>
<p>Now, we will add those back in using bower.</p>
<p>Add bower configuration file to the project. VS 2015 already have a template for it.</p>
<p><a href="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower1.jpg" target="_blank" rel="external"><img src="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower1.jpg" alt="bower1"></a></p>
<p>Edit the bower.json file, which has a package information we can / will define which library to use.</p>
<p>Type in ‘jquery’ as below and we will have an intellisense support automatically provided by VS 2015.</p>
<p><a href="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower3.png" target="_blank" rel="external"><img src="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower3.png" alt="bower3"></a></p>
<p>We can choose version as well, which also magically loaded as an option to choose.</p>
<p><a href="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower0.png" target="_blank" rel="external"><img src="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower0.png" alt="bower0"></a></p>
<p>By typing in library entries in dependencies section, all done about dependency definition.</p>
<div class="code-embed-wrapper"><br><pre class="code-embed-pre language-cpp ">{<br> “name”: “ASP.NET”,<br> “private”: true,<br> “dependencies”: {<br> “jquery”: “~3.1.0”,<br> “jquery-validate”: “~1.15.0”,<br> “bootstrap”: “~3.3.6”,<br> “lodash”: “~4.13.1”<br> },<br> “resolutions”: {<br> “jquery”: “&gt;= 1.7.2”<br> }<br>}</pre><br><div class="code-embed-infos"></div><br></div>

<p>Once save the bower.json file, VS 2015 automatically load all libraries listed, which is stored in /wwwroot/bin folder under your app project folder.</p>
<p><a href="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower6.jpg" target="_blank" rel="external"><img src="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower6.jpg" alt="bower6"></a></p>
<p>BTW, it contains source and bunch of other stuffs, we don’t really need.</p>
<p>Some just include all these files in the project and directly link to this folder. However, I would rather keep these folder separate from VS project and copy only jquery.min.js into Scripts folder so that we can keep the default MVC folder structure and also keep project folder as clean as possible. By doing this, we don’t need to commit any files under wwwroot/bin folder.</p>
<p>We will use Gulp here to automate the process to copy jquery.min.js from wwwroot/bin/jquery/dis/ folder to Scripts folder.</p>
<p><strong>5. Configure Gulp</strong></p>
<p>Add Gulp configuration file into root directory of VS project.</p>
<p><a href="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower4.jpg" target="_blank" rel="external"><img src="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower4.jpg" alt="bower4"></a></p>
<p>We need to understand gulp API and javascript a bit, but just follow the below for now, which will copy bootstrap and jquery into Scripts folder.</p>
<div class="code-embed-wrapper"><br><pre class="code-embed-pre language-c ">/// &lt;binding BeforeBuild=’default’ /&gt;<br>‘use strict’<br><br>var <em> = require(‘lodash’);<br>var gulp = require(‘gulp’);<br><br>gulp.task(‘default’, function () {<br> var js = {<br> js: [<br> ‘./wwwroot/lib/bootstrap/dist/js/bootstrap.min.js’,<br> ‘./wwwroot/lib/jquery/dist/jquery.min.js’,<br> ‘./wwwroot/lib/jquery-validate/dist/jquery.validate.min.js’,<br> ]<br> };
 </em>(js).forEach(function (js, type) {<br> gulp.src(js).pipe(gulp.dest(‘./Scripts’));<br> });<br>});</pre><br><div class="code-embed-infos"></div><br></div>

<p>Open [Task Runner Explore] from [View – Other Windows], we will be able to see ‘default’ task. If not, click the reload icon left top corner of Task Runner Explore window.</p>
<p><a href="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower01.png" target="_blank" rel="external"><img src="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower01.png" alt="bower01"></a></p>
<p>We can run it and see jquery.min.js and others libraries are copied over to Scripts folder.</p>
<p><a href="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower10.jpg" target="_blank" rel="external"><img src="http://www.moneystock.net/wp_e/wp-content/uploads/2016/07/bower10.jpg" alt="bower10"></a></p>
<p>We can bind ‘default’ task to ‘Before Build’, which will automatically run the task when we build the APS.Net MVC project.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;Background&lt;/h2&gt;&lt;p&gt;While looking for the JS libary to pop
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="asp.net" scheme="http://devkimchi.com/tags/asp-net/"/>
    
      <category term="Bower" scheme="http://devkimchi.com/tags/Bower/"/>
    
      <category term="Gulp" scheme="http://devkimchi.com/tags/Gulp/"/>
    
      <category term="MVC" scheme="http://devkimchi.com/tags/MVC/"/>
    
      <category term="node.js" scheme="http://devkimchi.com/tags/node-js/"/>
    
      <category term="npm" scheme="http://devkimchi.com/tags/npm/"/>
    
      <category term="visual studio 2015" scheme="http://devkimchi.com/tags/visual-studio-2015/"/>
    
      <category term="vs 2015" scheme="http://devkimchi.com/tags/vs-2015/"/>
    
  </entry>
  
  <entry>
    <title>Building .NET Core Application on Amazon Linux</title>
    <link href="http://devkimchi.com/2016/06/09/building-dotnet-core-application-on-amazon-linux/"/>
    <id>http://devkimchi.com/2016/06/09/building-dotnet-core-application-on-amazon-linux/</id>
    <published>2016-06-08T23:00:09.000Z</published>
    <updated>2016-09-13T23:02:26.718Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="https://blog.kloud.com.au/2016/05/31/building-dotnet-core-application-on-amazon-linux" target="_blank" rel="external">Building .NET Core Application on Amazon Linux</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p>In order to run .NET applications on Linux operating systems, <a href="http://www.mono-project.com" target="_blank" rel="external">Mono</a> used to be the only option. Now, Microsoft has released <a href="https://www.microsoft.com/net/core" target="_blank" rel="external">.NET Core</a> that can build and run .NET applications on any OS including Windows, OSX and Linux. In this post, we are going to install both .NET Core Framework RC1 and RC2, build and run a simple <code>Hello World</code> application, and compare RC1 to RC2.</p>
<h2 id="Installing-NET-Core-RC1"><a href="#Installing-NET-Core-RC1" class="headerlink" title="Installing .NET Core RC1"></a>Installing .NET Core RC1</h2><p>By following the official document, <a href="https://docs.asp.net/en/1.0.0-rc1/getting-started/installing-on-linux.html#installing-on-centos-7" target="_blank" rel="external">Installing ASP.NET 5 On Linux</a>, we can install .NET Core Framework onto Amazon Linux, which is a variation of RHEL/CentOS. In addition to this, we have to install Mono to run DNX because, in RC1, .NET Core only supports full framework like Mono.</p>
<p>However, <a href="http://www.mono-project.com/docs/getting-started/install/linux/#centos-7-fedora-19-and-later-and-derivatives" target="_blank" rel="external">the official document</a> from Mono doesn’t work well on Amazon Linux. When we follow the steps, we’re facing the dependency error:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/installing-mono-into-amazon-linux-02.png" alt=""></p>
<p>This needs to be sorted out before installing Mono. Fortunately, this <a href="http://blog.aliencube.org/ko/2016/05/21/installing-mono-into-amazon-linux" target="_blank" rel="external">post</a> (written in Korean, by the way) describes steps to install the missing dependencies on Amazon Linux. Once we install dependencies, then Mono can be easily installed.</p>
<p>Now, we’ve got Mono installed, and DNVM, DNU and DNX installed onto Amazon Linux. Then clone the following repository and run the console application sample.</p>
<ul>
<li><a href="https://github.com/devkimchi/Azure-Functions-AWS-Lambda-Sample" target="_blank" rel="external">https://github.com/devkimchi/Azure-Functions-AWS-Lambda-Sample</a></li>
</ul>
<p>There is a very high chance that our Amazon Linux VM doesn’t have git installed. In this case, before cloning the repo, git should be installed first. Then build and run it like:</p>
<script src="//gist.github.com/e720df8261afa0e17e6dcfb0131d6251.js"></script>
<p>Once we successfully run the code, we’ll be able to see like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/installing-dotnet-core-into-amazon-linux-01.png" alt=""></p>
<p>.NET Core also provides an interesting option, called <code>--native</code>. This enables developers to build an OS specific native binaries. With this native binaries, we can run that natively compiled binary on another Amazon Linux without .NET Core being installed. Follow the code bits and we should be able to see the natively compiled binaries.</p>
<p><a href="https://gist.github.com/justinyoo/dc222f44758cc3372c25b756fd1e1e5f" target="_blank" rel="external">https://gist.github.com/justinyoo/dc222f44758cc3372c25b756fd1e1e5f</a></p>
<p>However, we see a disappointing result back like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/installing-dotnet-core-into-amazon-linux-02.png" alt=""></p>
<p>Because we cannot install .NET Core CLR onto Amazon Linux, this native build is not possible.</p>
<h2 id="Installing-NET-Core-RC2"><a href="#Installing-NET-Core-RC2" class="headerlink" title="Installing .NET Core RC2"></a>Installing .NET Core RC2</h2><p>Releasing .NET Core RC2 makes Amazon Linux build and run .NET Core applications with Core CLR runtime. Mono is not required any longer. Follow the <a href="https://www.microsoft.com/net/core#centos" target="_blank" rel="external">official document</a> to install .NET Core on Amazon Linux. Again, Amazon Linux is a variation of RHEL/CentOS so we can use their instructions.</p>
<p>Once installation is complete, run the sample <code>Hello World</code> app from the instruction and we’ll be able to see the screen like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/installing-dotnet-core-into-amazon-linux-03.png" alt=""></p>
<p>How about the <code>--native</code> option in RC2?</p>
<p><a href="https://gist.github.com/justinyoo/c5beabbeb7820cbc6abff7d652310cd0" target="_blank" rel="external">https://gist.github.com/justinyoo/c5beabbeb7820cbc6abff7d652310cd0</a></p>
<p><a href="https://gist.github.com/justinyoo/804e1f182f44ba67cdc01067226fcc94" target="_blank" rel="external">https://gist.github.com/justinyoo/804e1f182f44ba67cdc01067226fcc94</a></p>
<p>When we check this option on either <code>dotnet build</code> or <code>dotnet publish</code>, we can’t find it. According to the <a href="https://github.com/dotnet/cli/issues/2803#issuecomment-216334290" target="_blank" rel="external">issue</a> on the GitHub repository, the <code>--native</code> option was excluded. Microsoft is planning to put this option back after the 1.0 official release.</p>
<h2 id="Why-Is-the-native-Option-Important"><a href="#Why-Is-the-native-Option-Important" class="headerlink" title="Why Is the --native Option Important?"></a>Why Is the <code>--native</code> Option Important?</h2><p>Now, we might have a question.</p>
<blockquote>
<p>Why is the <code>--native</code> option important to us?</p>
</blockquote>
<p>Actually, running .NET Core applications itself, there is no problem at all, with/without the option. However, there is a clear requirement to use native binary. For example, if we want to use our own binaries with <a href="http://docs.aws.amazon.com/lambda/latest/dg/nodejs-create-deployment-pkg.html" target="_blank" rel="external">AWS Lambda</a>, that native binary build option should be necessary. We hope this option is coming back sooner or later.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;https://blog.kloud.com.au/2016/05/31/building-dotnet-core-application-on-amazon-linux&quot; t
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term=".NET Core" scheme="http://devkimchi.com/tags/NET-Core/"/>
    
      <category term="Amazon Linux" scheme="http://devkimchi.com/tags/Amazon-Linux/"/>
    
      <category term="AWS Lambda" scheme="http://devkimchi.com/tags/AWS-Lambda/"/>
    
      <category term="Mono" scheme="http://devkimchi.com/tags/Mono/"/>
    
  </entry>
  
  <entry>
    <title>Installing Mono into Amazon Linux</title>
    <link href="http://devkimchi.com/2016/06/08/installing-mono-into-amazon-linux/"/>
    <id>http://devkimchi.com/2016/06/08/installing-mono-into-amazon-linux/</id>
    <published>2016-06-07T23:00:26.000Z</published>
    <updated>2016-09-13T12:11:48.469Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="https://blog.kloud.com.au/2016/05/30/installing-mono-into-amazon-linux" target="_blank" rel="external">Installing Mono into Amazon Linux</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p>There are a couple of ways to run C# applications on Linux operating systems. Before <a href="https://www.microsoft.com/net/core" target="_blank" rel="external">.NET Core</a>, <a href="http://www.mono-project.com" target="_blank" rel="external">Mono</a> used to be the only way for C# applications running on Linux machine. Each Linux distro has a different method to install Mono. In this post, we’ll walk through how to install Mono on Amazon Linux.</p>
<blockquote>
<p>NOTE: Amazon Linux 2016.03.1 was used for this post.</p>
<p>  <img src="http://blob.devkimchi.com/devkimchiwp/2016/06/installing-mono-into-amazon-linux-01.png" alt=""></p>
</blockquote>
<p>According to the <a href="http://www.mono-project.com/docs/getting-started/install/linux/#centos-7-fedora-19-and-later-and-derivatives" target="_blank" rel="external">official document</a>, we can follow the CentOS way. However, when we follow the instruction, we’ll get the following error like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/installing-mono-into-amazon-linux-02.png" alt=""></p>
<p>This can be sorted out by following the steps below:</p>
<p><a href="https://gist.github.com/justinyoo/fea4924afbe9b0bf06808a1861a8abb4" target="_blank" rel="external">https://gist.github.com/justinyoo/fea4924afbe9b0bf06808a1861a8abb4</a></p>
<p>First of all, take the root privilege by running the <code>sudo su</code> command. This MUST be returned after the installation to avoid further security breach. Taking the root permissions is not necessary. Instead, we MUST use <code>sudo</code> command every time we need to install something onto Amazon Linux.</p>
<p>Download the RPM package by executing the <code>wget</code> command, then install it. Once we complete installing the missing package, then follow the <a href="http://www.mono-project.com/docs/getting-started/install/linux/#centos-7-fedora-19-and-later-and-derivatives" target="_blank" rel="external">official document</a> again to set up <code>yum</code>.</p>
<p><a href="https://gist.github.com/justinyoo/6c25161d882ea234a6234d69d93c8877" target="_blank" rel="external">https://gist.github.com/justinyoo/6c25161d882ea234a6234d69d93c8877</a></p>
<p>If necessary, the following commands can help refresh cache.</p>
<p><a href="https://gist.github.com/justinyoo/aea2ec3152fef557359372ae088a69c6" target="_blank" rel="external">https://gist.github.com/justinyoo/aea2ec3152fef557359372ae088a69c6</a></p>
<p>Now, we’re ready for Mono installation. Try the following command for it.</p>
<p><a href="https://gist.github.com/justinyoo/8d37336332a177b156598fd13b4be216" target="_blank" rel="external">https://gist.github.com/justinyoo/8d37336332a177b156598fd13b4be216</a></p>
<p>All downloaded files for missing dependencies are no longer necessary. So delete them.</p>
<p><a href="https://gist.github.com/justinyoo/ba241f69845a2b6fb14e7004a5b7fb61" target="_blank" rel="external">https://gist.github.com/justinyoo/ba241f69845a2b6fb14e7004a5b7fb61</a></p>
<p>Mono installation completed! Now exit from the root privilege.</p>
<p><a href="https://gist.github.com/justinyoo/5ca61677101e90c468c293b5c86eb0a8" target="_blank" rel="external">https://gist.github.com/justinyoo/5ca61677101e90c468c293b5c86eb0a8</a></p>
<p>Try a demo code to confirm if Mono has been properly installed. A sample demo code can be found from the <a href="http://www.mono-project.com/docs/getting-started/mono-basics" target="_blank" rel="external">official document</a>. If everything is fine, we’ll be able to see the following result:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/installing-mono-into-amazon-linux-03.png" alt=""></p>
<p>We’ve installed Mono onto Amazon Linux. As it’s a variation of CentOS/RHEL, it should be as easy as what the document says. However, some missing dependencies need to be installed beforehand. In the next post, we’re going to install <a href="https://www.microsoft.com/net/core" target="_blank" rel="external">.NET Core</a> RC1 and RC2 onto Amazon Linux.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;https://blog.kloud.com.au/2016/05/30/installing-mono-into-amazon-linux&quot; target=&quot;_blank&quot; 
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="Amazon Linux" scheme="http://devkimchi.com/tags/Amazon-Linux/"/>
    
      <category term="Mono" scheme="http://devkimchi.com/tags/Mono/"/>
    
  </entry>
  
  <entry>
    <title>Entity Framework Core Data Migration through KUDU</title>
    <link href="http://devkimchi.com/2016/06/07/entity-framewoork-core-data-migration-through-kudu/"/>
    <id>http://devkimchi.com/2016/06/07/entity-framewoork-core-data-migration-through-kudu/</id>
    <published>2016-06-06T23:00:46.000Z</published>
    <updated>2016-09-13T12:11:48.468Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="https://blog.kloud.com.au/2016/04/16/entity-framewoork-7-data-migration-through-kudu" target="_blank" rel="external">Entity Framework 7 Data Migration through KUDU</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p>From DevOps perspective, everything needs to be automated in regards to application setup and deployment. There’s no exception for database migration. If database schema change occurs, it should be automatically applied before/after the application deployment. Unlike Entity Framework 6.x using PowerShell cmdlets for database migration, Entity Framework Core (EF Core) uses DNX for it.</p>
<h2 id="Applying-Database-Migration-with-EF-Core"><a href="#Applying-Database-Migration-with-EF-Core" class="headerlink" title="Applying Database Migration with EF Core"></a>Applying Database Migration with EF Core</h2><p>In EF Core RC1, updating database change can be done by running the following command:</p>
<p><a href="https://gist.github.com/justinyoo/26c5ba404159cd57850b18c1b7fd5b52" target="_blank" rel="external">https://gist.github.com/justinyoo/26c5ba404159cd57850b18c1b7fd5b52</a></p>
<p>If your <code>DbContext</code> is located in another project and your web application has a reference to it, then you can run the following command:</p>
<p><a href="https://gist.github.com/justinyoo/b7329197a7f60fd0cc88eea2f9bfbe80" target="_blank" rel="external">https://gist.github.com/justinyoo/b7329197a7f60fd0cc88eea2f9bfbe80</a></p>
<p>By running the command above within your build/deployment pipeline, your database change is easily applied to the existing database. Connectionstrings are defined in <code>appsettings.json</code> in your ASP.NET Core RC1 application.</p>
<blockquote>
<p>Visit <a href="https://docs.efproject.net" target="_blank" rel="external">https://docs.efproject.net</a> for more details.</p>
</blockquote>
<p>In most cases, there’s no issue to access to Azure SQL Database from your build/deployment server, as long as Azure SQL Database has a proper firewall setup. But what if your enterprise firewall doesn’t allow to connect to Azure SQL Database, like blocking the TCP port of 1433? Then we can’t run this command from our build/deployment server.</p>
<h2 id="REST-API-in-KUDU"><a href="#REST-API-in-KUDU" class="headerlink" title="REST API in KUDU"></a>REST API in KUDU</h2><p><a href="https://github.com/projectkudu/kudu" target="_blank" rel="external">KUDU</a> is basically a backend service engine for deployment tied to your Azure Website. If you are running any Azure App Service, your KUDU can be accessible via <code>https://your-azure-website.scm.azurewebsites.net</code>. It provides <a href="https://github.com/projectkudu/kudu/wiki/REST-API" target="_blank" rel="external">REST API</a> for website maintenance and one of its endpoint is <a href="https://github.com/projectkudu/kudu/wiki/REST-API#command" target="_blank" rel="external"><code>command</code></a>. Therefore, we can write a script, say <code>db-migration.cmd</code>, deploy it at the same time when the application is deployed, and run it through this REST API. The <code>db-migration.cmd</code> might look like:</p>
<p><a href="https://gist.github.com/justinyoo/19edb2eb788c3c5ccc31f457ddd42f67" target="_blank" rel="external">https://gist.github.com/justinyoo/19edb2eb788c3c5ccc31f457ddd42f67</a></p>
<p>So, the application is ready for database migration. Let’s write a PowerShell script to run the command. Make sure that we are using Azure Service Management (ASM) cmdlets.</p>
<blockquote>
<p>NOTE: You should login to ASM with appropriate subscription first.</p>
</blockquote>
<p><a href="https://gist.github.com/justinyoo/a2d36c1aa6ae678e9c3e18d03b838828" target="_blank" rel="external">https://gist.github.com/justinyoo/a2d36c1aa6ae678e9c3e18d03b838828</a></p>
<blockquote>
<p>NOTE: The <code>dir</code> property is where the actual command is run, which is the relative path to <code>D:\home</code> in Azure App Service.</p>
</blockquote>
<p>Running the PS script above will bring you to database migration completed within KUDU. Make sure that the <code>$result</code> object has an exit code of <code>0</code> by examining <code>$result.ExitCode</code>. If the exit code is other than <code>0</code>, database migration has come to fail.</p>
<p>So far, we have briefly looked at KUDU for Azure SQL Database migration. KUDU actually has many useful functions for monitoring, so it would be worth taking a look.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;https://blog.kloud.com.au/2016/04/16/entity-framewoork-7-data-migration-through-kudu&quot; ta
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="Data Migration" scheme="http://devkimchi.com/tags/Data-Migration/"/>
    
      <category term="Entity Framework" scheme="http://devkimchi.com/tags/Entity-Framework/"/>
    
      <category term="KUDU" scheme="http://devkimchi.com/tags/KUDU/"/>
    
  </entry>
  
  <entry>
    <title>Long Path Error While Publishing ASP.NET Core RC1 Applications</title>
    <link href="http://devkimchi.com/2016/06/06/long-path-error-while-publishing-aspnet-core-rc1-applications/"/>
    <id>http://devkimchi.com/2016/06/06/long-path-error-while-publishing-aspnet-core-rc1-applications/</id>
    <published>2016-06-05T23:00:45.000Z</published>
    <updated>2016-09-13T12:11:48.468Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="https://blog.kloud.com.au/2016/04/15/long-path-error-while-publishing-aspnet-core-applications" target="_blank" rel="external">Long Path Error While Publishing ASP.NET Core Applications</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p>If you are writing an ASP.NET Core RC1 application, there are chances to publish your app to either an Azure Website or another place, by right-mouse clicking in Visual Studio.</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/long-path-exception-01.png" alt=""></p>
<p>In most cases, it should be alright. However, if your app has a NuGet package with a long name, it would be an issue. You might be seeing an error like this:</p>
<blockquote>
<p>DNU(0,0): Error : The specified path, file name, or both are too long. The fully qualified file name must be less than 260 characters, and the directory name must be less than 248 characters.</p>
</blockquote>
<p>Yes, this is the notorious <a href="https://msdn.microsoft.com/en-us/library/system.io.pathtoolongexception.aspx" target="_blank" rel="external"><code>PathTooLongException</code></a> that Windows OS has had. There’s no silver bullet for easy fix for it. In this post, I’ll show you a couple of options that you might consider.</p>
<h2 id="Cause"><a href="#Cause" class="headerlink" title="Cause"></a>Cause</h2><p>While creating a package to publish, it uses the following path:</p>
<pre><code>C:\Users\[USERNAME]\AppData\Local\Temp\PublishTemp\[ProjectName][LengthOfProjectFullName]
`&lt;/pre&gt;

For example, I&apos;m using Justin as my `[USERNAME]` and my project has a name of `MyProject` and its full length is `163` then, the package publish path will look like:

&lt;pre&gt;`C:\Users\Justin\AppData\Local\Temp\PublishTemp\MyProject163
`&lt;/pre&gt;

In addition to that, an ASP.NET Core RC1 application creates three different directories under that path &amp;ndash; `approot`, `logs` and `wwwroot`. The `approot` path actually contains all NuGet packages and DNX runtime library. Here&apos;s the issue arising. If any of NuGet package has a very long name, it can&apos;t be fit into the temp folder. If any `node_module` has a deeper dependency, it will also throw an error for packaging.

Then, how can we solve the problem? I would suggest two approaches.

## Update Environment Variables

![](http://blob.devkimchi.com/devkimchiwp/2016/06/long-path-exception-02.png)

There are two environment variables &amp;ndash; `TEMP` and `TMP`. This determines your temp directory. Therefore, change it to a shorter ones like:

&lt;pre&gt;`TEMP=C:\Temp
TMP=C:\Temp
`&lt;/pre&gt;

This is the easiest and quickest way to fix the issue. However, the biggest caveat of this approach is that all other applications using those temp folder will be affected and we might have unwanted side effects. We need to find another way that only impacts on my current web application project.

## Update `.xproj`

Fortunately, when you open your `.xproj` file of your ASP.NET Core RC1 application, you will find the line almost at the bottom:

&lt;pre&gt;`&amp;lt;Import Project=&quot;$(VSToolsPath)\DNX\Microsoft.DNX.targets&quot; Condition=&quot;&apos;$(VSToolsPath)&apos; != &apos;&apos;&quot; /&amp;gt;

`&lt;/pre&gt;

This provides us with a great clue! Let&apos;s find out what we can to do with that `Microsoft.DNX.targets` file. First of all, open the `Microsoft.DNX.targets` that is located in `C:\Program Files (x86)\MSBuild\Microsoft\VisualStudio\v14.0\DNX`. It also points another file, `$(_WebPublishTargetsPath)\Web\Microsoft.DNX.Publishing.targets` that is located in the `C:\Program Files (x86)\MSBuild\Microsoft\VisualStudio\v14.0\Web` directory. Open the file.

Then, find the `Global Properties` section and you will find:

&lt;pre&gt;`&amp;lt;PropertyGroup&amp;gt;  
  &amp;lt;PublishTempFolderName Condition=&quot;&apos;$(PublishTempFolderName)&apos; == &apos;&apos;&quot;&amp;gt;$([System.IO.Path]::GetFileNameWithoutExtension($(MSBuildProjectFullPath)))$(MSBuildProjectFullPath.Length)&amp;lt;/PublishTempFolderName&amp;gt;
  &amp;lt;PublishOutputPathNoTrailingSlash Condition=&quot;&apos;$(PublishOutputPathNoTrailingSlash)&apos; == &apos;&apos;&quot;&amp;gt;$([System.IO.Path]::GetTempPath())PublishTemp\$(PublishTempFolderName)&amp;lt;/PublishOutputPathNoTrailingSlash&amp;gt;
  &amp;lt;PublishOutputPath Condition=&quot;&apos;$(PublishOutputPath)&apos; == &apos;&apos;&quot;&amp;gt;$(PublishOutputPathNoTrailingSlash)\&amp;lt;/PublishOutputPath&amp;gt;
  &amp;lt;PublishPowerShellVersion Condition=&quot;&apos;$(PublishPowerShellVersion)&apos; == &apos;&apos;&quot;&amp;gt;1.0.1&amp;lt;/PublishPowerShellVersion&amp;gt;
&amp;lt;/PropertyGroup&amp;gt;
`&lt;/pre&gt;

Here&apos;s the magic property &amp;ndash; `PublishOutputPathNoTrailingSlash`. This property is used at the bottom of that `targets` file like:

&lt;pre&gt;`&amp;lt;Dnu
  RuntimeToolingDirectory =&quot;$(RuntimeToolingDirectory)&quot;
  ProjectFolder=&quot;$(MSBuildProjectDirectory)&quot;
  Project=&quot;$(KPackWorkingDirectory)&quot;
  Command=&quot;publish&quot;
  Runtime=&quot;$(FinalPublishVersion)&quot;
  WwwRoot=&quot;$(WebRoot)&quot;
  WwwRootOut=&quot;$(WwwRootOut)&quot;
  NoSource=&quot;$(NoSourceFlag)&quot;
  Quiet=&quot;$(QuietFlag)&quot;
  IncludeSymbols =&quot;$(IncludeSymbolsFlag)&quot;
  Native =&quot;$(NativeFlag)&quot;
  Configuration=&quot;$(PublishConfiguration)&quot;

  Out=&quot;$(PublishOutputPathNoTrailingSlash)&quot;

  ExternalToolsPath=&quot;$(ExternalToolsPath)&quot;
  IsFilePreview=&quot;$(FilePreview)&quot; 
  IISCommand=&quot;$(IISCommand)&quot;
  EnvironmentVariables=&quot;@(DnuPublishEnvironmentVariables)&quot;/&amp;gt;
`&lt;/pre&gt;

This `Dnu` node basically emulates the `msdeploy.exe` so the `Out` attribute defines the output folder where the package is published. Now, we know what needs to be changed. Within our `.xproj` file, we can add this `PublishOutputPathNoTrailingSlash` node like:

&lt;pre&gt;`&amp;lt;PropertyGroup&amp;gt;
  &amp;lt;PublishOutputPathNoTrailingSlash Condition=&quot;&apos;$(PublishOutputPathNoTrailingSlash)&apos; == &apos;&apos;&quot;&amp;gt;C:\Temp\$(MSBuildProjectName)&amp;lt;/PublishOutputPathNoTrailingSlash&amp;gt;
&amp;lt;/PropertyGroup&amp;gt;
&amp;lt;Import Project=&quot;$(VSToolsPath)\DNX\Microsoft.DNX.targets&quot; Condition=&quot;&apos;$(VSToolsPath)&apos; != &apos;&apos;&quot; /&amp;gt;
</code></pre><p>Once you add the property, save it and restart your Visual Studio to get this change applied to your ASP.NET Core application project. Run the <code>Publish</code> menu again and it will not fail. This is a better approach comparing to the first one, because it doesn’t impact on other applications on Windows.</p>
<p>Of course, if you use <code>msdeploy</code> by your hand, it wouldn’t be an issue as you can choose the <code>-output</code> value based on your preference.</p>
<p>So far, we have had a walkaround to fix the <code>PathTooLongException</code> issue during the deployment of your ASP.NET Core RC1 application. Fortunately, this restriction will be removed soon.</p>
<div><br>&gt; Microsoft removes 260 characters for NTFS Path limit in new Windows 10 insider preview | Great news!!! <a href="https://t.co/uT2iqx3gqi" target="_blank" rel="external">https://t.co/uT2iqx3gqi</a><br>&gt; &mdash; Jeff Wouters [MVP] (@JeffWouters) <a href="https://twitter.com/JeffWouters/status/737165967772549120" target="_blank" rel="external">May 30, 2016</a><br><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script><br></div>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;https://blog.kloud.com.au/2016/04/15/long-path-error-while-publishing-aspnet-core-applic
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="ASP.NET Core" scheme="http://devkimchi.com/tags/ASP-NET-Core/"/>
    
      <category term="PathTooLongException" scheme="http://devkimchi.com/tags/PathTooLongException/"/>
    
      <category term="RC1" scheme="http://devkimchi.com/tags/RC1/"/>
    
  </entry>
  
  <entry>
    <title>Creating Accounts on Azure SQL Database through PowerShell</title>
    <link href="http://devkimchi.com/2016/06/05/creating-accounts-on-azure-sql-database-through-powershell/"/>
    <id>http://devkimchi.com/2016/06/05/creating-accounts-on-azure-sql-database-through-powershell/</id>
    <published>2016-06-05T11:30:04.000Z</published>
    <updated>2016-09-13T12:11:48.468Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="https://blog.kloud.com.au/2016/04/12/creating-accounts-on-azure-sql-database-through-powershell-automation" target="_blank" rel="external">Creating Accounts on Azure SQL Database through PowerShell Automation</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p>In the previous post, <a href="http://devkimchi.com/2702/creating-login-account-and-user-on-azure-sql">Creating Login Account and User on Azure SQL</a>, we have briefly walked through how to create login accounts on Azure SQL Database through SSMS. Using SSMS is of course the very convenient way. However, as a DevOps engineer, I want to automate this process through PowerShell. In this post, we’re going to walk through how to achieve this goal.</p>
<h2 id="Step-1-Create-Azure-SQL-Database"><a href="#Step-1-Create-Azure-SQL-Database" class="headerlink" title="Step #1: Create Azure SQL Database"></a>Step #1: Create Azure SQL Database</h2><p>First of all, we need an Azure SQL Database. It can be easily done by running an ARM template in PowerShell like:</p>
<p><a href="https://gist.github.com/justinyoo/226b02f30f3626adb4e151471aa1ae98" target="_blank" rel="external">https://gist.github.com/justinyoo/226b02f30f3626adb4e151471aa1ae98</a></p>
<p>We’re not going to dig it further, as this is beyond our topic. Now, we’ve got an Azure SQL Database.</p>
<h2 id="Step-2-Create-SQL-Script-for-Login-Account"><a href="#Step-2-Create-SQL-Script-for-Login-Account" class="headerlink" title="Step #2: Create SQL Script for Login Account"></a>Step #2: Create SQL Script for Login Account</h2><p>In <a href="http://devkimchi.com/2702/creating-login-account-and-user-on-azure-sql">the previous post</a>, we used the following SQL script:</p>
<p><a href="https://gist.github.com/justinyoo/a0fcf112bda27c09ac54747c56e5fe11" target="_blank" rel="external">https://gist.github.com/justinyoo/a0fcf112bda27c09ac54747c56e5fe11</a></p>
<p>Now, we’re going to automate this process by providing username and password as parameters to an SQL script. The main part of the script above is <code>CREATE LOGIN ...</code>, so we slightly modify it like:</p>
<p><a href="https://gist.github.com/justinyoo/71d22c8fa0e6da633858017a68d3dce5" target="_blank" rel="external">https://gist.github.com/justinyoo/71d22c8fa0e6da633858017a68d3dce5</a></p>
<p>Now the SQL script is ready.</p>
<h2 id="Step-3-Create-PowerShell-Script-for-Login-Account"><a href="#Step-3-Create-PowerShell-Script-for-Login-Account" class="headerlink" title="Step #3: Create PowerShell Script for Login Account"></a>Step #3: Create PowerShell Script for Login Account</h2><p>We need to execute this in PowerShell. Look at the following PowerShell script:</p>
<p><a href="https://gist.github.com/justinyoo/071607ca0ab18f7eac56926a4167c3f4" target="_blank" rel="external">https://gist.github.com/justinyoo/071607ca0ab18f7eac56926a4167c3f4</a></p>
<p>Looks familiar? Yes, indeed. It’s basically the same as using ADO.NET in ASP.NET applications. Let’s run this PowerShell script. Woops! Something went wrong. We can’t run the SQL script. What’s happening?</p>
<h2 id="Step-4-Update-SQL-Script-for-Login-Account"><a href="#Step-4-Update-SQL-Script-for-Login-Account" class="headerlink" title="Step #4: Update SQL Script for Login Account"></a>Step #4: Update SQL Script for Login Account</h2><p><code>CREATE LOGIN</code> won’t take variables. In other words, the SQL script above will never work unless modified to take variables. In this case, we don’t want to but should use dynamic SQL, which is ugly. Therefore, let’s update the SQL script:</p>
<p><a href="https://gist.github.com/justinyoo/7daf3cd112d003ee67e6a02cd8fee783" target="_blank" rel="external">https://gist.github.com/justinyoo/7daf3cd112d003ee67e6a02cd8fee783</a></p>
<p>Then run the PowerShell script again and it will work. Please note that using dynamic SQL here wouldn’t be a big issue, as all those scripts are not exposed to public anyway.</p>
<h2 id="Step-5-Update-SQL-Script-for-User-Login"><a href="#Step-5-Update-SQL-Script-for-User-Login" class="headerlink" title="Step #5: Update SQL Script for User Login"></a>Step #5: Update SQL Script for User Login</h2><p>In a similar way, we need to create a user in the Azure SQL Database. This also requires dynamic SQL like:</p>
<p><a href="https://gist.github.com/justinyoo/29d2c173d7c76838be44b329615bd4d2" target="_blank" rel="external">https://gist.github.com/justinyoo/29d2c173d7c76838be44b329615bd4d2</a></p>
<p>This is to create a user with a <code>db_owner</code> role. In order for the user to have only limited permissions, use the following dynamic SQL script:</p>
<p><a href="https://gist.github.com/justinyoo/8f910737a59677bf3f0f7a82787c318a" target="_blank" rel="external">https://gist.github.com/justinyoo/8f910737a59677bf3f0f7a82787c318a</a></p>
<h2 id="Step-6-Modify-PowerShell-Script-for-User-Login"><a href="#Step-6-Modify-PowerShell-Script-for-User-Login" class="headerlink" title="Step #6: Modify PowerShell Script for User Login"></a>Step #6: Modify PowerShell Script for User Login</h2><p>In order to run the SQL script right above, run the following PowerShell script:</p>
<p><a href="https://gist.github.com/justinyoo/ea1237b06e463e030f6cf072f2a6e878" target="_blank" rel="external">https://gist.github.com/justinyoo/ea1237b06e463e030f6cf072f2a6e878</a></p>
<p>So far, we have walked through how we can use PowerShell script to create login accounts and user logins on Azure SQL Database. With this approach, DevOps engineers will be easily able to create accounts on Azure SQL Database by running PowerShell script on their build server or deployment server.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;https://blog.kloud.com.au/2016/04/12/creating-accounts-on-azure-sql-database-through-pow
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="PowerShell" scheme="http://devkimchi.com/tags/PowerShell/"/>
    
      <category term="Azure SQL" scheme="http://devkimchi.com/tags/Azure-SQL/"/>
    
      <category term="Automation" scheme="http://devkimchi.com/tags/Automation/"/>
    
      <category term="DevOps" scheme="http://devkimchi.com/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>Creating Login Account and User on Azure SQL</title>
    <link href="http://devkimchi.com/2016/06/02/creating-login-account-and-user-on-azure-sql/"/>
    <id>http://devkimchi.com/2016/06/02/creating-login-account-and-user-on-azure-sql/</id>
    <published>2016-06-02T13:24:36.000Z</published>
    <updated>2016-09-13T12:11:48.465Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="https://blog.kloud.com.au/2016/04/08/azure-sql-pro-tip-creating-login-account-and-user" target="_blank" rel="external">Azure SQL Pro Tip – Creating Login Account and User</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p>With Azure Resource Manager (ARM), while creating an Azure SQL Database instance, we can only set up an admin account. As we all know, using this admin account is not safe in most cases. Therefore, we need to create another accounts with fewer privileges.</p>
<p>However, unlike MS SQL Server, Azure SQL Database has some restrictions. Those restrictions also apply to create login accounts and users. In this post, we are going to create login accounts with limited permissions on Azure SQL Database.</p>
<h2 id="Creating-Login-Account"><a href="#Creating-Login-Account" class="headerlink" title="Creating Login Account"></a>Creating Login Account</h2><p>With ARM, once an admin account is ready, we need to connect to the SQL Database instance with the admin account, using its credentials.</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/azure-sql-pro-tips-login-accounts-01.png" alt=""></p>
<p>Once you connect to the Azure SQL Database through SSMS, you will be able to see the screen like above. Make sure that you are now on the <code>master</code> database. Then run the following SQL query:</p>
<p><a href="https://gist.github.com/justinyoo/a0fcf112bda27c09ac54747c56e5fe11" target="_blank" rel="external">https://gist.github.com/justinyoo/a0fcf112bda27c09ac54747c56e5fe11</a></p>
<ul>
<li>&lt;LOGIN_ACCOUNT&gt; is the one you want to create.</li>
<li>&lt;ACCOUNT_PASSWORD&gt; is the password of the account you want to create.</li>
</ul>
<blockquote>
<p>NOTE: We can’t use the <code>DEFAULT_DATABASE</code> option when creating a login account as we’re on Azure SQL Database. For more details, find <a href="https://msdn.microsoft.com/en-us/library/ms189751.aspx" target="_blank" rel="external">this MSDN document</a>.</p>
</blockquote>
<p>The first query is to check if the login account already exists and, if exists, drop it. Of course you can skip this part. The second query is actually to create the login account.</p>
<p>If you are on a database other than <code>master</code> and run the SQL query above, you will get an error message like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/azure-sql-pro-tips-login-accounts-02.png" alt=""></p>
<p>Make sure that you are on the <code>master</code> database. :-) We have created a new login account. Let’s move onto the next step.</p>
<h2 id="Creating-User-on-Database-with-Appropriate-Permissions"><a href="#Creating-User-on-Database-with-Appropriate-Permissions" class="headerlink" title="Creating User on Database with Appropriate Permissions"></a>Creating User on Database with Appropriate Permissions</h2><p>In order to create a user and grant permissions on the user, in SSMS, we usually do like:</p>
<p><a href="https://gist.github.com/justinyoo/3813ae27c5eb273a03162e9fc1bae943" target="_blank" rel="external">https://gist.github.com/justinyoo/3813ae27c5eb273a03162e9fc1bae943</a></p>
<p>However, we are on Azure SQL Database. You will see the error message like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/azure-sql-pro-tips-login-accounts-03.png" alt=""></p>
<p>According to the MSDN document, <a href="https://msdn.microsoft.com/en-us/library/ms188366.aspx" target="_blank" rel="external">USE (Transact-SQL)</a>, we can’t use the <code>USE</code> statement on Azure SQL Database.</p>
<blockquote>
<p>In Azure SQL Database, the database parameter can only refer to the current database. The <code>USE</code> statement does not switch between databases, error code 40508 is returned. To change databases, <strong>you must directly connect to the database</strong>.</p>
</blockquote>
<p>Yes, we need to directly connect to the database. How can we do it?</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/azure-sql-pro-tips-login-accounts-04.png" alt=""></p>
<p>As the admin account uses the <code>master</code> database as its default one, instead of using the &lt;default&gt; database, we should specify a particular database name like above. After directly connect to the database, run the following SQL query to create a user and give permissions to the user:</p>
<p><a href="https://gist.github.com/justinyoo/e447b39019f437be802b3d96847f6dbc" target="_blank" rel="external">https://gist.github.com/justinyoo/e447b39019f437be802b3d96847f6dbc</a></p>
<p>This script is to create a user and give a <code>db_owner</code> privilege. If you want more restricted one, try the following:</p>
<p><a href="https://gist.github.com/justinyoo/584c8d5173d81e8faa0ef0a0b88de454" target="_blank" rel="external">https://gist.github.com/justinyoo/584c8d5173d81e8faa0ef0a0b88de454</a></p>
<p>This only offers the user with <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code> and <code>DELETE</code> permissions.</p>
<p>That’s it. So far, we have walked through how we could create a login account and a user of a database on Azure SQL Database. If we can create a login account with limited privileges, we can use Azure SQL Database with fewer worries.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;https://blog.kloud.com.au/2016/04/08/azure-sql-pro-tip-creating-login-account-and-user&quot; 
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="Azure SQL" scheme="http://devkimchi.com/tags/Azure-SQL/"/>
    
  </entry>
  
  <entry>
    <title>Global Exception Handling on ASP.NET Core Applications</title>
    <link href="http://devkimchi.com/2016/06/01/global-exception-handling-on-aspnet-core-applications/"/>
    <id>http://devkimchi.com/2016/06/01/global-exception-handling-on-aspnet-core-applications/</id>
    <published>2016-06-01T12:53:01.000Z</published>
    <updated>2016-09-13T12:11:48.466Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="https://blog.kloud.com.au/2016/03/23/aspnet-core-tips-and-tricks-global-exception-handling" target="_blank" rel="external">ASP.NET Core Tips &amp; Tricks – Global Exception Handling</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p>Exception handling is one of most important but irritating jobs for developers. There are tons of articles about the importance of exception handling. Fortunately, ASP.NET Core application has got a lot of improvement for exception handling through the request/response pipeline. In this article, we’re going to have a brief look how we can handle exceptions.</p>
<blockquote>
<p>Sample application can be found here: <a href="https://github.com/devkimchi/ASP.NET-Core-Tips-and-Tricks-Sample" target="_blank" rel="external">https://github.com/devkimchi/ASP.NET-Core-Tips-and-Tricks-Sample</a></p>
</blockquote>
<h2 id="Global-Exception-Filter-OWIN-Pipeline"><a href="#Global-Exception-Filter-OWIN-Pipeline" class="headerlink" title="Global Exception Filter - OWIN Pipeline"></a>Global Exception Filter - OWIN Pipeline</h2><p>Unlike ASP.NET MVC applications, ASP.NET Core applications only use OWIN pipelines to handle requests and responses. In order to handle exceptions, <code>UseExceptionHandler()</code> middleware extension is provided out of the box. Therefore, it can be easily implemented like this:</p>
<p><a href="https://gist.github.com/justinyoo/6955a665cc6fcaa4f6c6" target="_blank" rel="external">https://gist.github.com/justinyoo/6955a665cc6fcaa4f6c6</a></p>
<p>However, if you want to do more control, creating a custom exception filter class would be recommended. The following code is a simple <code>GlobalExceptionFilter</code> class:</p>
<p><a href="https://gist.github.com/justinyoo/4c3526deee32f9358557" target="_blank" rel="external">https://gist.github.com/justinyoo/4c3526deee32f9358557</a></p>
<p><a href="https://www.nuget.org/packages/Microsoft.AspNet.Mvc" target="_blank" rel="external"><code>Microsoft.AspNet.Mvc</code></a> package provides an interface called <code>IExceptionFilter</code>. It declares the <code>OnException()</code> method so the <code>GlobalExceptionHandler</code> implements it. As this class accepts the <code>ILoggerFactory</code> instance as its constructor parameter, we can write logs when an exception is thrown. It is implemented with <code>log4Net</code>, <code>NLog</code> and <code>ApplicationInsights</code> libraries. You can choose anything in your taste.</p>
<p>So, the <code>GlobalExceptionFilter</code> class can be resolved within the <code>ConfigureServices()</code> method on <code>Startup.cs</code> like:</p>
<p><a href="https://gist.github.com/justinyoo/9e98ecbe651733a18aa9" target="_blank" rel="external">https://gist.github.com/justinyoo/9e98ecbe651733a18aa9</a></p>
<p>Then, raise an exception within a controller and you will be able to see the error log like this:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/06/global-exception-handling-01.png" alt=""></p>
<h2 id="Exception-Handling-outside-OWIN-Pipeline"><a href="#Exception-Handling-outside-OWIN-Pipeline" class="headerlink" title="Exception Handling outside OWIN Pipeline"></a>Exception Handling outside OWIN Pipeline</h2><p>As stated above, the <code>GlobalExceptionFilter</code> only works within the OWIN pipeline. How about handling outside OWIN pipeline? There are only three places to handle exceptions outside OWIN pipeline &ndash; <code>Startup()</code> constructor, <code>ConfigureServices()</code> method and <code>Configure()</code> method. Let’s have a look at the code below:</p>
<p><a href="https://gist.github.com/justinyoo/269f45544ee710417353" target="_blank" rel="external">https://gist.github.com/justinyoo/269f45544ee710417353</a></p>
<p>This is how the <code>Configure()</code> method handles exceptions. Note that this is the only place where we can handle exceptions. In other words, the other two places, <code>Startup()</code> and <code>ConfigureServices()</code> can throw exceptions but can’t handle them. It is because of the <code>IApplicationBuilder.Run()</code> method. This method takes <code>HttpContext</code> instance to handle exceptions. Hence, using <code>try...catch</code> block writes response messages to browsers.</p>
<p>One question still remains. How can the other two places handle exceptions? Here’s a trick for them:</p>
<p><a href="https://gist.github.com/justinyoo/df11d6f4aa5e1753c30e" target="_blank" rel="external">https://gist.github.com/justinyoo/df11d6f4aa5e1753c30e</a></p>
<p>All codes should be surrounded by <code>try...catch</code> block. If any exception is thrown, the <code>_exceptions</code> field having type of <code>Dictionary&amp;lt;string, List&amp;lt;Exception&amp;gt;&amp;gt;</code> stores the exception. If any exception is thrown from <code>Startup()</code> or <code>ConfigureServices()</code>, this is handled within the <code>Configure()</code> method like above.</p>
<p>Now, we can handle all exceptions inside/outside OWIN pipeline. As this is just an example, if you apply this approach into your production code, you need to carefully review and do a bit of refactoring.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;https://blog.kloud.com.au/2016/03/23/aspnet-core-tips-and-tricks-global-exception-handli
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="ASP.NET Core" scheme="http://devkimchi.com/tags/ASP-NET-Core/"/>
    
      <category term="Global Exception Handling" scheme="http://devkimchi.com/tags/Global-Exception-Handling/"/>
    
  </entry>
  
  <entry>
    <title>When Importing Swagger 2.0 Docs into API Management</title>
    <link href="http://devkimchi.com/2016/05/31/when-importing-swagger-20-docs-into-api-management/"/>
    <id>http://devkimchi.com/2016/05/31/when-importing-swagger-20-docs-into-api-management/</id>
    <published>2016-05-31T12:42:54.000Z</published>
    <updated>2016-09-13T12:11:48.464Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="https://blog.kloud.com.au/2016/03/03/api-management-tips-and-tricks-importing-swagger-20-docs" target="_blank" rel="external">API Management Tips &amp; Tricks – Importing Swagger 2.0 Docs</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p><a href="https://azure.microsoft.com/en-us/services/api-management" target="_blank" rel="external">API Management (APIM)</a> offers many features for consumers to use by providing a unified endpoint. In order to achieve this consolidation, importing existing API definitions is one of its key functionalities. APIM supports both document types in <a href="https://wadl.java.net" target="_blank" rel="external">WADL</a> and <a href="http://swagger.io" target="_blank" rel="external">Swagger</a> to import APIs. In this post, we’re going to discuss what we should know when dealing with Swagger documents.</p>
<h2 id="The-Issue"><a href="#The-Issue" class="headerlink" title="The Issue"></a>The Issue</h2><p>Importing Swagger document into APIM is pretty straight forward by following <a href="https://azure.microsoft.com/en-us/documentation/articles/api-management-get-started/#create-api" target="_blank" rel="external">this Azure document</a>. There’s no issue when you import Swagger 1.2 documents. However, if you’re intending to import Swagger 2.0 ones, you’ll be facing the screen like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2016/05/apim-with-swagger-01.png" alt=""></p>
<p>It gets stuck here forever with no indication. Your <code>swagger.json</code> file is all valid, by the way. What happens?</p>
<h2 id="Findings"><a href="#Findings" class="headerlink" title="Findings"></a>Findings</h2><p>If you’re building an API app with .NET Framework 4.5+, using <a href="https://github.com/domaindrivendev/Swashbuckle" target="_blank" rel="external">Swashbuckle</a> library, it would be fine. However, if you’re building the app with ASP.NET Core, it does bring you a headache. Firstly, look at your <code>Startup.cs</code> file. The <code>ConfigureService</code> method looks like:</p>
<p><a href="https://gist.github.com/justinyoo/a6f584a0a8b3ea256909" target="_blank" rel="external">https://gist.github.com/justinyoo/a6f584a0a8b3ea256909</a></p>
<p>In addition to this, the <code>Configure</code> method might look like:</p>
<p><a href="https://gist.github.com/justinyoo/2f6cf1a3674f38804133" target="_blank" rel="external">https://gist.github.com/justinyoo/2f6cf1a3674f38804133</a></p>
<p>This is the basic settings for swagger for your Web API. Now run your API app and get the <code>swagger.json</code> document. It might look like:</p>
<p><a href="https://gist.github.com/justinyoo/5d3ef5b3a9f64ee46485" target="_blank" rel="external">https://gist.github.com/justinyoo/5d3ef5b3a9f64ee46485</a></p>
<p>Nothing seems to be wrong, right? This <code>swagger.json</code> file is even well validated, if you’re using another service like <a href="https://swaggerhub.com" target="_blank" rel="external">swaggerhub.com</a>. How come this is not imported into APIM? Take a look at the modified <code>swagger.json</code>:</p>
<p><a href="https://gist.github.com/justinyoo/077fb118c751ae1034fc" target="_blank" rel="external">https://gist.github.com/justinyoo/077fb118c751ae1034fc</a></p>
<p>Can you identify what the differences are? You’re right. The modified one includes two additional properties &ndash; <code>host</code> and <code>schemes</code>. <a href="http://swagger.io/specification" target="_blank" rel="external">Swagger specification</a> clearly declares that both are <strong>NOT</strong> required. However, APIM <strong>DOES</strong> require both properties to be included in the <code>swagger.json</code> document.</p>
<p>So, how can we sort this out?</p>
<h2 id="Resolution"><a href="#Resolution" class="headerlink" title="Resolution"></a>Resolution</h2><p>For your app in .NET 4.5+, just make sure that your <code>SwaggerConfig.cs</code> has activated those options with proper settings:</p>
<ul>
<li><code>SwaggerDocsConfig.Schemes(new[] { &quot;http&quot;, &quot;https&quot; });</code></li>
<li><code>SwaggerDocsConfig.RootUrl(req =&amp;gt; GetRootUrlFromAppConfig());</code></li>
</ul>
<p>In your ASP.NET Core app, it might be tricky as you should implement the <code>IDocumentFilter</code> interface. Here’s a sample code:</p>
<p><a href="https://gist.github.com/justinyoo/b1068979411fb2f0d6f2" target="_blank" rel="external">https://gist.github.com/justinyoo/b1068979411fb2f0d6f2</a></p>
<p>And this <code>SchemaDocumentFilter</code> should be added into your <code>ConfigureService</code> method in <code>Startup.cs</code>:</p>
<p><a href="https://gist.github.com/justinyoo/44845d980dfe2ef77942" target="_blank" rel="external">https://gist.github.com/justinyoo/44845d980dfe2ef77942</a></p>
<p>Once you complete this, then import your <code>swagger.json</code> to APIM and <em>viola!</em> You’re now an APIM guru!</p>
<p>So far, we’ve had a brief look at an issue on APIM with <code>swagger.json</code> and its resolution. The sample code used in this post can be found at <a href="https://github.com/devkimchi/ASP.NET-Core-Tips-and-Tricks-Sample" target="_blank" rel="external">https://github.com/devkimchi/ASP.NET-Core-Tips-and-Tricks-Sample</a>.</p>
<p>Happy coding!</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;https://blog.kloud.com.au/2016/03/03/api-management-tips-and-tricks-importing-swagger-20
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="Swagger" scheme="http://devkimchi.com/tags/Swagger/"/>
    
      <category term="API Management" scheme="http://devkimchi.com/tags/API-Management/"/>
    
  </entry>
  
  <entry>
    <title>Microsoft Integration Roadmap and choosing right technologies for Cloud Integration</title>
    <link href="http://devkimchi.com/2016/02/14/microsoft-integration-roadmap-and-choosing-right-technologies-for-cloud-integration/"/>
    <id>http://devkimchi.com/2016/02/14/microsoft-integration-roadmap-and-choosing-right-technologies-for-cloud-integration/</id>
    <published>2016-02-13T23:14:02.000Z</published>
    <updated>2016-09-13T12:11:48.462Z</updated>
    
    <content type="html"><![CDATA[<div id="toc"><strong>Table of Contents</strong><br><br><em>   <a href="http://ahkim.com/Microsoft-Integration-Roadmap-More-Considerations.html#Integration_Roadmap_-_a_gift_" target="_blank" rel="external">1. Integration Roadmap - a gift?</a>
</em>   <a href="http://ahkim.com/Microsoft-Integration-Roadmap-More-Considerations.html#More_to_consider..." target="_blank" rel="external">2. More to consider…</a><br><em>   <a href="http://ahkim.com/Microsoft-Integration-Roadmap-More-Considerations.html#Then_What_More_" target="_blank" rel="external">3. Then What More?</a>

    </em>   <a href="http://ahkim.com/Microsoft-Integration-Roadmap-More-Considerations.html#Remote_Procedure_Call" target="_blank" rel="external">3.1. Remote Procedure Call</a><br>    <em>   <a href="http://ahkim.com/Microsoft-Integration-Roadmap-More-Considerations.html#Asynchronous_Messaging" target="_blank" rel="external">3.2. Asynchronous Messaging</a>
    </em>   <a href="http://ahkim.com/Microsoft-Integration-Roadmap-More-Considerations.html#Shared_Database" target="_blank" rel="external">3.3. Shared Database</a><br>    <em>   <a href="http://ahkim.com/Microsoft-Integration-Roadmap-More-Considerations.html#File_Transfer" target="_blank" rel="external">3.4. File Transfer</a>

</em>   <a href="http://ahkim.com/Microsoft-Integration-Roadmap-More-Considerations.html#Conclusion" target="_blank" rel="external">4. Conclusion</a><br></div>

<h3 id="1-Integration-Roadmap-a-gift"><a href="#1-Integration-Roadmap-a-gift" class="headerlink" title="1. Integration Roadmap - a gift?"></a>1. Integration Roadmap - a gift?</h3><p>Microsoft released a document detailing their roadmap to integration on 24th December 2015. This was a pleasant Christmas gift for many integration experts using Microsoft technologies because it clarified Microsoft’s integration strategy which was somewhat vague before.</p>
<p>If you haven’t unopened the box yet, you can download it <a href="http://aka.ms/integrationroadmap" target="_blank" rel="external">here</a>. Key points are as below.</p>
<blockquote>
<p>Continuing commitment to BizTalk Server, with our 10th release of BizTalk Server in Q4 2016.</p>
</blockquote>
<div class="highlight"><br><br>    1. BizTalk is not dead and there is more to come.<br>    `<br>    </div>

<pre><code>&gt; Expansion of our iPaaS vision to provide a comprehensive and compelling integration offering spanning both traditional and modern integration requirements. Preview refresh in January 2016 and General Availability (GA) in April 2016.

&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;`2\. Both traditional and modern integration requirements will be catered with Microsoft&apos;s integration offering.  
`&lt;/pre&gt;
&lt;/div&gt;

&gt; Deliver our iPaaS offering on premises through Logic Apps on Azure Stack in preview around Q3 2016 and GA around end of the year.

&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;`3\. Along with other Azure Services, Azure Logic Apps will be available through the Azure Stack in future. Azure Stack enables customer data centres to use Azure Services. This means Azure Logic Apps could also be used for On-Premise Integration as well as BizTalk Server.  
`&lt;/pre&gt;
&lt;/div&gt;

&gt; Strong roadmap and significant investments to ensure we continue to be recognized as a market leader in integration.

&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;`4\. Microsoft continues to invest to cater all possible integration requirements through its existing and developing technologies.
`&lt;/pre&gt;
&lt;/div&gt;

&gt; The next release of Host Integration Server is planned on the same timeline as BizTalk Server below.

&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;`5\. Host Integration Server also gets released with improved feature sets.  
</code></pre><p></p>
<p>This shows the direction Microsoft integration is heading toward. The Azure App Service team is responsible for delivering integration technologies at Microsoft. They are responsible for BizTalk Server, Host Integration Server, Azure Logic Apps, Azure API Apps and Azure API Management. This is probably why they have simplified Microsoft’s Integration Offering as per the diagram below.</p>
<p><img src="http://i.imgur.com/zJxFHVc.png" alt=""></p>
<p>However, this does not mean Microsoft technologies not included above can’t be used for integration. For example, Azure Service Bus is still a key technology for hybrid integration scenarios. I will introduce others in a later section.</p>
<h3 id="2-More-to-consider…"><a href="#2-More-to-consider…" class="headerlink" title="2. More to consider…"></a>2. More to consider…</h3><p>Following diagram illustrates very simplified integration technology choices we have with current Microsoft’s integration offering - BizTalk Server, BizTalk Services and Logic Apps.</p>
<p><img src="http://i.imgur.com/ofWdPq3.png" alt=""></p>
<p>Though this tells us what works where, it’s a bit overly simplified and in fact, I see a lot of confusion coming from customers. It kind of gives you an impression that all that is necessary for Cloud Integration is just Azure Logic Apps (or with API Apps). This is not the case.</p>
<h3 id="3-Then-What-More"><a href="#3-Then-What-More" class="headerlink" title="3. Then What More?"></a>3. Then What More?</h3><p>Choosing technologies for On-Premise Integration is easy. If we narrow the scope to Microsoft offering only, you have BizTalk Server for Application Integration and SQL Server Integration Service for Data Integration.</p>
<p>But choosing right technologies for Cloud Integration requires a lot more to consider as it still has same level of integration needs (Data aggregation/replication, single source of truth, distributed/long-running processes, B2B integration, etc.) as before and introduces completely new challenging integration scenarios (On-Premise to Cloud, Cloud to Cloud, Cloud to On-Premise). Also more importantly, integration patterns should be considered before drilling into each scenario.</p>
<p>Here, I would like to list common integration patterns and technologies for Cloud Integration. Please note Microsoft technologies <strong>bold</strong>ed are not necessarily included in the Integration roadmap above.</p>
<h4 id="3-1-Remote-Procedure-Call"><a href="#3-1-Remote-Procedure-Call" class="headerlink" title="3.1. Remote Procedure Call"></a>3.1. Remote Procedure Call</h4><p>: Request data at the source and wait until it receives a response. Typically synchronous. Brokers support this but often not needed. Thus, fits well into modern Integration in the integration roadmap.</p>
<p><img src="http://i.imgur.com/53DtZDt.png" alt=""></p>
<h4 id="3-2-Asynchronous-Messaging"><a href="#3-2-Asynchronous-Messaging" class="headerlink" title="3.2. Asynchronous Messaging"></a>3.2. Asynchronous Messaging</h4><p>: Fire and forget message exchange. Brokers can help to guarantee message delivery when reliability matters.</p>
<p><img src="http://i.imgur.com/fyJAh94.png" alt=""></p>
<h4 id="3-3-Shared-Database"><a href="#3-3-Shared-Database" class="headerlink" title="3.3. Shared Database"></a>3.3. Shared Database</h4><p>: When disparate (both On-Premise and Cloud) applications uses a single, authoritative source.</p>
<p><img src="http://i.imgur.com/VUHjxGj.png" alt=""></p>
<h4 id="3-4-File-Transfer"><a href="#3-4-File-Transfer" class="headerlink" title="3.4. File Transfer"></a>3.4. File Transfer</h4><p>: Data integration - think of scenarios for Cloud based Data-warehousing. ETL tools and VPN technologies help.</p>
<p><img src="http://i.imgur.com/q0wZm06.png" alt=""></p>
<h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>It is important to understand that integrating systems is inherently complex and it can be even more so with Cloud Integration. Realising this and knowing how to choose right technologies to help is a key to succeed. While Microsoft’s integration roadmap helps clarifying what are available, there is more to consider and more options that Microsoft offers for each possible scenario.</p>
]]></content>
    
    <summary type="html">
    
      &lt;div id=&quot;toc&quot;&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;em&gt;   &lt;a href=&quot;http://ahkim.com/Microsoft-Integration-Roadmap-More-Considerations.h
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="BizTalk" scheme="http://devkimchi.com/tags/BizTalk/"/>
    
      <category term="Azure" scheme="http://devkimchi.com/tags/Azure/"/>
    
      <category term="Integration" scheme="http://devkimchi.com/tags/Integration/"/>
    
      <category term="Logic Apps" scheme="http://devkimchi.com/tags/Logic-Apps/"/>
    
  </entry>
  
  <entry>
    <title>Running Application with Office 365 Graph API in App-only Mode</title>
    <link href="http://devkimchi.com/2015/12/16/implementing-application-with-office365-graph-api-in-app-only-mode/"/>
    <id>http://devkimchi.com/2015/12/16/implementing-application-with-office365-graph-api-in-app-only-mode/</id>
    <published>2015-12-16T09:13:16.000Z</published>
    <updated>2016-09-13T12:11:48.462Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="http://blog.kloud.com.au/2015/12/14/implementing-application-with-o365-graph-api-in-app-only-mode" target="_blank" rel="external">Implementing Application with Office 365 Graph API in App-only Mode</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p>Microsoft has recently release <a href="https://graph.microsoft.com" target="_blank" rel="external">Microsoft Graph</a> to easily integrate Office 365 resources with applications. Graph API basically provides one single endpoint to call bunch of Web APIs to get access Office 365 resources.</p>
<p>In order to use Graph API from another application, the application must be registered in <a href="https://azure.microsoft.com/en-us/services/active-directory" target="_blank" rel="external">Azure Active Directory (AAD)</a> first. When the application is registered, we can choose how the application is permitted to use resources &ndash; application permissions or delegate permissions. The latter one typically requires users to provide user credentials like username and password to get a proper access token. However, there must be requirements that the application doesn’t require users credentials but should directly access to Office 365 resources, which is called <code>app-only</code> mode. For example, a back-end Web API application doesn’t require user credentials to communicate with Graph API. There are many articles on the Internet dealing with user credentials but not many articles coping with this <code>app-only</code> mode. In this post, I will walk through how to register an application as <code>app-only</code> mode and consume Graph API through the registered application.</p>
<blockquote>
<p>The sample code used here can be found <a href="https://github.com/devkimchi/Graph-API-App-Only-Web-API-Sample" target="_blank" rel="external">here</a>. This sample application is built-in ASP.NET 5 and ASP.NET MVC 6. Therefore, in order to get the best development experience, I would recommend using <a href="https://www.visualstudio.com" target="_blank" rel="external">Visual Studio 2015</a>.</p>
</blockquote>
<h2 id="Registering-Application"><a href="#Registering-Application" class="headerlink" title="Registering Application"></a>Registering Application</h2><p>OK. First thing goes first. As the sample application is using AAD and Graph API, it’s a mandatory to register this app on your AAD first. Please follow the steps below.</p>
<h3 id="Create-User-Account-on-AAD"><a href="#Create-User-Account-on-AAD" class="headerlink" title="Create User Account on AAD"></a>Create User Account on AAD</h3><blockquote>
<p>You can skip this step, if you have already got a user account on AAD.<br>  <strong>NOTE</strong>: Microsoft Account won’t work with this sample app.</p>
</blockquote>
<p>Create a user account on AAD tenant. Once created, the user account should be a co-administrator of the Azure subscription that is currently being used.</p>
<h3 id="Register-Application-to-AAD"><a href="#Register-Application-to-AAD" class="headerlink" title="Register Application to AAD"></a>Register Application to AAD</h3><ul>
<li>Login to <a href="https://manage.windowsazure.com" target="_blank" rel="external">Azure Management Portal</a>.</li>
<li>Select Active Directory.</li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-01.png" alt=""></p>
<ul>
<li>Create a new application.</li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-02.png" alt=""></p>
<ul>
<li>Choose the <code>Add an application my organization is developing</code> option.</li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-03.png" alt=""></p>
<ul>
<li>Enter the application name like <code>Graph API App-only Sample</code> and select the <code>Web Application and/or Web API</code> option.</li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-04.png" alt=""></p>
<ul>
<li>Enter <code>https://(tenant-name)/GraphApiAppOnlySample</code> for both fields. <code>(tenant-name)</code> should look like <code>contoso.onmicrosoft.com</code>. Please note that both won’t be used at all.</li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-05.png" alt=""></p>
<p>Now the app has been registered.</p>
<h3 id="Configure-Application"><a href="#Configure-Application" class="headerlink" title="Configure Application"></a>Configure Application</h3><ul>
<li>Once the app is registered, click the <code>configure</code> tab.</li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-06.png" alt=""></p>
<ul>
<li>Get the <code>Client ID</code>.</li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-07.png" alt=""></p>
<ul>
<li>Get the secret key. Note that the key is only displayed once after click the <code>Save</code> button at the bottom.</li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-08.png" alt=""></p>
<ul>
<li>Add another application called <code>Microsoft Graph</code></li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-10.png" alt=""></p>
<ul>
<li>Give “Read directory data” permission to <code>Microsoft Graph</code>, as this permission is only necessary to run the sample app.</li>
</ul>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-11.png" alt=""></p>
<blockquote>
<p><strong>ATTENTION</strong>: In the production environment, appropriate number of application permissions <strong>MUST</strong> be given to avoid any security breach.</p>
</blockquote>
<p>The app has been configured.</p>
<h3 id="Update-Settings-in-Sample-Application"><a href="#Update-Settings-in-Sample-Application" class="headerlink" title="Update Settings in Sample Application"></a>Update Settings in Sample Application</h3><p>As the app has been registered and configured, the sample Web API app should be setup with appropriate settings. Firstly, open <code>appsettings.json</code></p>
<p><a href="https://gist.github.com/justinyoo/6cf1a84889c954bf84bd" target="_blank" rel="external">https://gist.github.com/justinyoo/6cf1a84889c954bf84bd</a></p>
<p>Then change values:</p>
<ul>
<li><code>Tenant</code>: <code>contoso.onmicrosoft.com</code> to your tenant name.</li>
<li><code>ClientId</code>: Client ID from the app.</li>
<li><code>ClientSecret</code>: Secret key from the app.</li>
<li><code>AppId</code>: <code>contoso.onmicrosoft.com</code> to your tenant name.</li>
</ul>
<h3 id="Trust-IIS-or-IIS-Express-with-a-Self-signed-Certificate"><a href="#Trust-IIS-or-IIS-Express-with-a-Self-signed-Certificate" class="headerlink" title="Trust IIS or IIS Express with a Self-signed Certificate"></a>Trust IIS or IIS Express with a Self-signed Certificate</h3><blockquote>
<ul>
<li>You can skip this step, if you intend to publish this app to Azure.</li>
<li>You can skip this step, if you already have a self-signed certificate on your root certificate storage.</li>
</ul>
</blockquote>
<p>All communications with AAD and Graph API are performed through a secure channel (SSL/TLS), this sample app <strong>MUST</strong> be signed with a root certificate. However, this is a developer’s local environment, so a self-signed certificate should be issued and stored as a root certificate. If you don’t store the self-signed certificate, you’ll see the following message popped up when you run VS2015.</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/graph-api-app-only-sample-12.png" alt=""></p>
<p>The following steps show how to register self-signed certificate to the root certificate store using PowerShell.</p>
<h4 id="Check-Self-signed-Certificate"><a href="#Check-Self-signed-Certificate" class="headerlink" title="Check Self-signed Certificate"></a>Check Self-signed Certificate</h4><p>First, Check if you have a self-signed certificate in your personal certificate store.</p>
<p><a href="https://gist.github.com/justinyoo/d05587bd30807df09925" target="_blank" rel="external">https://gist.github.com/justinyoo/d05587bd30807df09925</a></p>
<p>If there’s no certificate with name of <code>CN=localhost</code>, you should create the one using <code>makecert.exe</code>. The easiest way to execute <code>makecert.exe</code> is to run <code>Developer Command Prompt for VS2015</code>.</p>
<p><a href="https://gist.github.com/justinyoo/98646323b78c729ed359" target="_blank" rel="external">https://gist.github.com/justinyoo/98646323b78c729ed359</a></p>
<ul>
<li><code>-r</code>: Create a self signed certificate.</li>
<li><code>-pe</code>: Mark generated private key as exportable.</li>
<li><code>-n</code>: Certificate subject X509 name. eg) <code>-n &quot;CN=localhost&quot;</code></li>
<li><code>-b</code>: Start of the validity period in <code>mm/dd/yyyy</code> format; default to now.</li>
<li><code>-e</code>: End of validity period in <code>mm/dd/yyyy</code> format; defaults to 2039.</li>
<li><code>-ss</code>: Subject’s certificate store name that stores the output certificate. eg) <code>-ss My</code></li>
<li><code>-len</code>: Generated Key Length (Bits). Default to <code>2048</code> for ‘RSA’ and <code>512</code> for ‘DSS’.</li>
</ul>
<h4 id="Store-Self-signed-Certificate-to-Root-Store"><a href="#Store-Self-signed-Certificate-to-Root-Store" class="headerlink" title="Store Self-signed Certificate to Root Store"></a>Store Self-signed Certificate to Root Store</h4><p>Second, store the self-signed certificate to the root store.</p>
<p><a href="https://gist.github.com/justinyoo/2d04aa42e5d28d6a7bc6" target="_blank" rel="external">https://gist.github.com/justinyoo/2d04aa42e5d28d6a7bc6</a></p>
<p>Finally, you can verify the self-signed certificate has been stored into the root store.</p>
<p><a href="https://gist.github.com/justinyoo/47c8e1b42defa37f08eb" target="_blank" rel="external">https://gist.github.com/justinyoo/47c8e1b42defa37f08eb</a></p>
<h3 id="Build-and-Run-Sample-Web-API-Application"><a href="#Build-and-Run-Sample-Web-API-Application" class="headerlink" title="Build and Run Sample Web API Application"></a>Build and Run Sample Web API Application</h3><p>All setup has been completed! Now, build the solution in Visual Studio 2015 and punch <code>F5</code> key to get into the <code>Debug</code> mode. Then you’ll get a JSON response of your tenant organisation details. How does it work? Let’s look into the code.</p>
<h2 id="Get-Access-Token-from-AAD-Using-ADAL"><a href="#Get-Access-Token-from-AAD-Using-ADAL" class="headerlink" title="Get Access Token from AAD Using ADAL"></a>Get Access Token from AAD Using ADAL</h2><p>In order to get an access token from AAD, we need to setup <code>AuthenticationContext</code> instance and call a method to get one. The code snippet below is an extract from the sample application.</p>
<p><a href="https://gist.github.com/justinyoo/40b18d2a61aef293db81" target="_blank" rel="external">https://gist.github.com/justinyoo/40b18d2a61aef293db81</a></p>
<p>The <code>graphApp</code> instance is created from <code>appsettings.json</code> and injected to the controller. With this instance, both <code>AuthenticationContext</code> instance and <code>ClientCredential</code> instance have been created. Note that the <code>ClientCredential</code> instance only uses <code>clientId</code> and <code>clientSecret</code>, not user credentials. In other words, this sample application won’t require any user to login and provide their login details. Let’s see the actual <code>Get()</code> method.</p>
<p><a href="https://gist.github.com/justinyoo/52c28375b1867b24f650" target="_blank" rel="external">https://gist.github.com/justinyoo/52c28375b1867b24f650</a></p>
<p>This is the part to get access token. The <code>AuthenticationContext</code> instance sends a request for Graph API with the <code>ClientCredential</code> instance only containing <code>clientId</code> and <code>clientSecret</code>. When the authentication fails, the <code>Get()</code> action will return the exception details as a JSON format. The <code>authResult</code> instance now contains access token.</p>
<h2 id="Call-Graph-API-with-Access-Token"><a href="#Call-Graph-API-with-Access-Token" class="headerlink" title="Call Graph API with Access Token"></a>Call Graph API with Access Token</h2><p>Now, we have the access token. In the same action method, let’s see how it is consumed to call Graph API.</p>
<p><a href="https://gist.github.com/justinyoo/913586550283cb6519fb" target="_blank" rel="external">https://gist.github.com/justinyoo/913586550283cb6519fb</a></p>
<p>The access token is set to the request header. In this sample code, we call <code>organization</code> details through Graph API. If you use <a href="http://www.telerik.com/fiddler" target="_blank" rel="external">Fiddler</a>, send a request to the application and you will see the full response details.</p>
<p>So far, we have had a brief look how to implement a simple Web API application as <code>app-only</code> mode to consume Graph API. As stated above, this sample application is not for production use unless proper permissions are given. Once all appropriate permissions are setup, you can easily customise this app for your integration purpose. Hope this will help your development.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;http://blog.kloud.com.au/2015/12/14/implementing-application-with-o365-graph-api-in-app-
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="Web API" scheme="http://devkimchi.com/tags/Web-API/"/>
    
      <category term="App-Only" scheme="http://devkimchi.com/tags/App-Only/"/>
    
      <category term="ASP.NET 5" scheme="http://devkimchi.com/tags/ASP-NET-5/"/>
    
      <category term="ASP.NET MVC 6" scheme="http://devkimchi.com/tags/ASP-NET-MVC-6/"/>
    
      <category term="Graph API" scheme="http://devkimchi.com/tags/Graph-API/"/>
    
      <category term="Microsoft Graph" scheme="http://devkimchi.com/tags/Microsoft-Graph/"/>
    
      <category term="O365" scheme="http://devkimchi.com/tags/O365/"/>
    
      <category term="Office 365" scheme="http://devkimchi.com/tags/Office-365/"/>
    
  </entry>
  
  <entry>
    <title>Resource Manager Cmdlets in Azure PowerShell 1.0</title>
    <link href="http://devkimchi.com/2015/12/02/resource-manager-cmdlets-in-azure-powershell-1-0/"/>
    <id>http://devkimchi.com/2015/12/02/resource-manager-cmdlets-in-azure-powershell-1-0/</id>
    <published>2015-12-02T12:00:10.000Z</published>
    <updated>2016-09-13T12:11:48.456Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="http://blog.kloud.com.au/2015/11/24/resource-manager-cmdlets-in-azure-powershell-1-0" target="_blank" rel="external">Resource Manager Cmdlets in Azure PowerShell 1.0</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p><a href="https://azure.microsoft.com" target="_blank" rel="external">Azure</a> recently launched the 1.0 version of <a href="https://github.com/Azure/azure-powershell" target="_blank" rel="external">PowerShell</a> cmdlets. The changes are huge, including new Azure Resource Manager (ARM), which resulted in <a href="https://github.com/Azure/azure-powershell/wiki/Deprecation-of-Switch-AzureMode-in-Azure-PowerShell" target="_blank" rel="external">deprecating <code>Azure-SwitchMode</code></a> between ASM and ARM. In this post, we only have a brief look at how new PowerShell cmdlets for ARM have been introduced, especially for managing resource groups and templates.</p>
<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><p>In order to get the newest Azure PowerShell, using <a href="http://www.microsoft.com/web/downloads/platform.aspx" target="_blank" rel="external">MS Web Platform Installer</a> is the quickest and easiest way.</p>
<p><img src="https://kloudsolutions.files.wordpress.com/2015/11/new-arm-cmdlets-01.png" alt=""></p>
<blockquote>
<p>Note: At the moment of writing, the released date of Azure PowerShell is Nov. 9th, 2015.</p>
</blockquote>
<p>Of course, there are other ways to install the latest version of Azure PowerShell, but this is beyond the scope of this post.</p>
<h2 id="New-Set-of-Cmdlets"><a href="#New-Set-of-Cmdlets" class="headerlink" title="New Set of Cmdlets"></a>New Set of Cmdlets</h2><p>Now, the new version of Azure PowerShell has been installed. Run PowerShell ISE with an Administrator privilege. As always, run <code>Update-Help</code> to get the all help files up-to-date. Then try the following command:</p>
<p><a href="https://gist.github.com/justinyoo/e9bee00c2eca5368e20c" target="_blank" rel="external">https://gist.github.com/justinyoo/e9bee00c2eca5368e20c</a></p>
<p>If you can’t see anything, don’t worry. You can restart ISE or even <a href="http://stackoverflow.com/questions/23939486/azure-powershell-cmds-not-working-in-ise#25318136" target="_blank" rel="external">restart your PC</a>.</p>
<p>Alternatively, you can check those cmdlets through ISE like:</p>
<p><img src="https://kloudsolutions.files.wordpress.com/2015/11/new-arm-cmdlets-02.png" alt=""></p>
<p><img src="https://kloudsolutions.files.wordpress.com/2015/11/new-arm-cmdlets-03.png" alt=""></p>
<p>Can you find any differences comparing to the previous version of cmdlets? All cmdlets are named as patterns of <code>[action]-AzureRm[noun]</code>. For example, in order to get the list of resource groups, you can run <code>Get-AzureRmResourceGroup</code>. The result will look like:</p>
<p><a href="https://gist.github.com/justinyoo/70a1b4da8a2ff02befa3" target="_blank" rel="external">https://gist.github.com/justinyoo/70a1b4da8a2ff02befa3</a></p>
<p>Now, let’s try to setup a simple web application infrastructure. For the web application, at least one website and database is required. In addition to them, for telemetry purpose, <a href="https://azure.microsoft.com/en-us/services/application-insights" target="_blank" rel="external">ApplicationInsights</a> might be necessary.</p>
<h2 id="Create-a-Resource-Group"><a href="#Create-a-Resource-Group" class="headerlink" title="Create a Resource Group"></a>Create a Resource Group</h2><p>For those infrastructure, we need a resource group. Try the following cmdlets in that order:</p>
<p><a href="https://gist.github.com/justinyoo/71a9fb54da840e1e66b0" target="_blank" rel="external">https://gist.github.com/justinyoo/71a9fb54da840e1e66b0</a></p>
<p>Can you find out the differences from the old cmdlets?</p>
<table><br><thead><br><tr><br>  <th>Old Cmdlets</th><br>  <th>New Cmdlets</th><br></tr><br></thead><br><tbody><br><tr><br>  <td><code>Get-AzureAccount</code></td><br>  <td><code>Login-AzureRmAccount</code></td><br></tr><br><tr><br>  <td><code>Get-AzureSubscription</code></td><br>  <td><code>Get-AzureRmSubscription</code></td><br></tr><br><tr><br>  <td><code>Select-AzureSubscription</code></td><br>  <td><code>Select-AzureRmSubscription</code></td><br></tr><br></tbody><br></table>

<p>As stated above, all cmdlets now have names of <code>AzureRm</code> instead of <code>Azure</code>. Once you complete choosing your subscription, if you have more than one subscription, it’s time to create a resource group for those infrastructure items. It might be worth having a look <a href="https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-infrastructure-services-implementation-guidelines" target="_blank" rel="external">naming guidelines for Azure resources</a>. Let’s try it.</p>
<table><br><thead><br><tr><br>  <th>Old Cmdlets</th><br>  <th>New Cmdlets</th><br></tr><br></thead><br><tbody><br><tr><br>  <td><code>New-AzureResourceGroup</code></td><br>  <td><code>New-AzureRmResourceGroup</code></td><br></tr><br></tbody><br></table>

<p>Therefore, enter the following to create a resource group:</p>
<p><a href="https://gist.github.com/justinyoo/3b18cf63a68f748ceb10" target="_blank" rel="external">https://gist.github.com/justinyoo/3b18cf63a68f748ceb10</a></p>
<p>The resource group is now named as <code>ase-dev-rg-sample</code> and created in the <strong>Australia Southeast (Melbourne)</strong> region. Let’s move onto the next step, setting up all resources using a template.</p>
<h2 id="Setup-Resources-with-Azure-Resource-Template"><a href="#Setup-Resources-with-Azure-Resource-Template" class="headerlink" title="Setup Resources with Azure Resource Template"></a>Setup Resources with Azure Resource Template</h2><p>Fortunately, there is a template for our purpose on GitHub repository: <a href="https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-sql-database" target="_blank" rel="external">https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-sql-database</a>.</p>
<table><br><thead><br><tr><br>  <th>Old Cmdlets</th><br>  <th>New Cmdlets</th><br></tr><br></thead><br><tbody><br><tr><br>  <td><code>New-AzureResourceGroupDeployment</code></td><br>  <td><code>New-AzureRmResourceGroupDeployment</code></td><br></tr><br></tbody><br></table>

<p>Use the new cmdlet and add all resources into the group:</p>
<p><a href="https://gist.github.com/justinyoo/988133a974a5a3000a52" target="_blank" rel="external">https://gist.github.com/justinyoo/988133a974a5a3000a52</a></p>
<p>As you can see, we set the template file directly from <a href="https://github.com/Azure/azure-quickstart-templates/blob/master/201-web-app-sql-database/azuredeploy.json" target="_blank" rel="external">GitHub</a> and left parameter source. Therefore, it will ask to type necessary parameters:</p>
<p><a href="https://gist.github.com/justinyoo/b2137fd8989eba28fbc3" target="_blank" rel="external">https://gist.github.com/justinyoo/b2137fd8989eba28fbc3</a></p>
<p>Once everything is entered, as I put <code>-Verbose</code> parameter, all setup details will be displayed as well as result:</p>
<p><a href="https://gist.github.com/justinyoo/8fb9a0643d54e9c75e09" target="_blank" rel="external">https://gist.github.com/justinyoo/8fb9a0643d54e9c75e09</a></p>
<p>Check out the <a href="https://portal.azure.com" target="_blank" rel="external">Azure Portal</a> whether all defined resources have been deployed or not.</p>
<p><img src="https://kloudsolutions.files.wordpress.com/2015/11/new-arm-cmdlets-04.png" alt=""></p>
<p>Everything has been smoothly deployed.</p>
<p>We have so far had a quick look of ARM with resource group management. There are more cmdlets in Azure PowerShell to control individual resources more precisely. I’m not going to deep dive too much here, but it’s much worth trying other cmdlets for your infrastructure setup purpose. This is even more powerful than before.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;http://blog.kloud.com.au/2015/11/24/resource-manager-cmdlets-in-azure-powershell-1-0&quot; ta
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="PowerShell" scheme="http://devkimchi.com/tags/PowerShell/"/>
    
      <category term="Azure" scheme="http://devkimchi.com/tags/Azure/"/>
    
      <category term="ARM" scheme="http://devkimchi.com/tags/ARM/"/>
    
      <category term="Azure Resource Manager" scheme="http://devkimchi.com/tags/Azure-Resource-Manager/"/>
    
      <category term="Resource Group" scheme="http://devkimchi.com/tags/Resource-Group/"/>
    
  </entry>
  
  <entry>
    <title>Creating Entity-Filtered Service Context for Dynamics CRM 2015</title>
    <link href="http://devkimchi.com/2015/12/02/creating-entity-filtered-service-context-for-dynamics-crm-2015/"/>
    <id>http://devkimchi.com/2015/12/02/creating-entity-filtered-service-context-for-dynamics-crm-2015/</id>
    <published>2015-12-02T02:00:25.000Z</published>
    <updated>2016-09-13T12:11:48.461Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>This is a cross-posting of <a href="http://blog.kloud.com.au/2015/12/02/testable-entity-filtering-for-service-context-on-dynamics-crm-2015" target="_blank" rel="external">Testable Entity Filtering for Service Context on Dynamics CRM 2015</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud</a>.</p>
</blockquote>
<p><a href="http://www.microsoft.com/crm" target="_blank" rel="external">MS Dynamics CRM</a> provides several web service endpoints. This is one of those endpoints, for organisation service.</p>
<p><a href="https://gist.github.com/justinyoo/96e5b5dd3a25343044a7" target="_blank" rel="external">https://gist.github.com/justinyoo/96e5b5dd3a25343044a7</a></p>
<p>One of the greatest benefits using this endpoint is to create a context class derived from <a href="https://msdn.microsoft.com/en-us/library/microsoft.xrm.client.crmorganizationservicecontext.aspx" target="_blank" rel="external"><code>CrmOrganizationServiceContext</code></a>, which works as like <a href="https://msdn.microsoft.com/en-us/library/system.data.entity.dbcontext.aspx" target="_blank" rel="external"><code>DbContext</code></a> from <a href="http://www.asp.net/entity-framework" target="_blank" rel="external">Entity Framework</a>. The context class can be generated by <code>CrmSvcUtil.exe</code> that is shipped in <a href="https://msdn.microsoft.com/en-us/library/hh547453.aspx" target="_blank" rel="external">CRM SDK</a>.</p>
<p>When you directly run the following command in the Command Prompt screen, or put the command in <code>build.bat</code> and run the batch file, one single file defined in the <code>/out</code> parameter is generated:</p>
<p><a href="https://gist.github.com/justinyoo/4229dbb8b385e744db5c" target="_blank" rel="external">https://gist.github.com/justinyoo/4229dbb8b385e744db5c</a></p>
<p>However, there are problems using the generated file:</p>
<ul>
<li>There are number of entities defined in CRM, but there is only one file generated.</li>
<li>Each entity can have tens to hundreds of fields (or properties).</li>
<li>Not all entities are necessary for generation.</li>
</ul>
<p>Due to the reasons stated above, even if a very new CRM instance is used to generate the context file, the size of the file is more than 6.5MB, which is huge. If CRM is customised based on business requirements, more entities and fields are generated, which results in the bigger size of the generated file. It is not desirable. I’m not happy at all.</p>
<p>Fortunately, <code>CrmSvcUtil.exe</code> provides an interface called <code>ICodeWriterFilterService</code>. With this interface, only selected entities are filtered and generated as strongly-typed classes. In addition to this, those filtering entities can be set up in a various type of configuration files such as XML, JSON or YAML. In this post, I’m going to show how to implement <code>ICodeWriterFilterService</code> to filter out entities defined in a configuration file in XML, JSON or YAML.</p>
<blockquote>
<p>The complete sample code can be found at <a href="https://github.com/devkimchi/Dynamics-CRM-2015-Filtering-Sample" target="_blank" rel="external">https://github.com/devkimchi/Dynamics-CRM-2015-Filtering-Sample</a></p>
</blockquote>
<h2 id="Implementing-ICodeWriterFilterService"><a href="#Implementing-ICodeWriterFilterService" class="headerlink" title="Implementing ICodeWriterFilterService"></a>Implementing <code>ICodeWriterFilterService</code></h2><p>Within the CRM SDK or <a href="https://msdn.microsoft.com/en-us/library/hh547384.aspx" target="_blank" rel="external">this page</a>, you can find the sample code to generate extension codes. Based on that sample code, a new <code>EntityFilteringService</code> class is created for our purpose:</p>
<p><a href="https://gist.github.com/justinyoo/8b4f82dc7bafca780c15" target="_blank" rel="external">https://gist.github.com/justinyoo/8b4f82dc7bafca780c15</a></p>
<ul>
<li>You can find the <code>GenerateEntity()</code> method. It accepts <a href="https://msdn.microsoft.com/en-us/library/microsoft.xrm.sdk.metadata.entitymetadata.aspx" target="_blank" rel="external"><code>EntityMetadata</code></a> instance as a parameter and validates its entity name &ndash; if it’s valid, create the entity; otherwise ignore it.</li>
<li>You can also find <code>IFilterItemCollection</code> interface within the constructor. This creates an instance deserialised from a setup file for entity filtering and validates the entity name.</li>
</ul>
<p>That’s what the <code>EntityFilteringService</code> only does. Once <code>IFilterItemCollection</code> instance is properly implemented, it just works. Now, let’s create classes implementing that interface.</p>
<h2 id="Implementing-IFiterItemCollection"><a href="#Implementing-IFiterItemCollection" class="headerlink" title="Implementing IFiterItemCollection"></a>Implementing <code>IFiterItemCollection</code></h2><p>First of all, the <code>IFilterItemCollection</code> interface defines one method, <code>IsValidEntity(entityName)</code>.</p>
<p><a href="https://gist.github.com/justinyoo/1379daed7fa0d5213067" target="_blank" rel="external">https://gist.github.com/justinyoo/1379daed7fa0d5213067</a></p>
<p>Then that method is implemented in the <code>FilterItemCollection</code> class.</p>
<p><a href="https://gist.github.com/justinyoo/13a0f7179bb2350fe835" target="_blank" rel="external">https://gist.github.com/justinyoo/13a0f7179bb2350fe835</a></p>
<p>Please note that this <code>FilterItemCollectionClass</code> has the modifier of <code>abstract</code>. As stated above, the filtering setup file can be any format like XML, JSON or YAML. Therefore any corresponding class should inherit this base class. Let’s move onto implementing concrete classes for each setup file format.</p>
<h3 id="XmlFilterItemCollection"><a href="#XmlFilterItemCollection" class="headerlink" title="XmlFilterItemCollection"></a><code>XmlFilterItemCollection</code></h3><p>If you are an XML person, setup file might be <code>filter.xml</code> and its structure looks like:</p>
<p><a href="https://gist.github.com/justinyoo/cbb3d12a9bab9583899f" target="_blank" rel="external">https://gist.github.com/justinyoo/cbb3d12a9bab9583899f</a></p>
<p>Therefore, read the XML file and deserialise it.</p>
<p><a href="https://gist.github.com/justinyoo/462b1cf564c8421c34e2" target="_blank" rel="external">https://gist.github.com/justinyoo/462b1cf564c8421c34e2</a></p>
<h3 id="JsonFilterItemCollection"><a href="#JsonFilterItemCollection" class="headerlink" title="JsonFilterItemCollection"></a><code>JsonFilterItemCollection</code></h3><p>If you prefer JSON, create <code>filter.json</code> like:</p>
<p><a href="https://gist.github.com/justinyoo/dd1eb19e012221078b1b" target="_blank" rel="external">https://gist.github.com/justinyoo/dd1eb19e012221078b1b</a></p>
<p>And deserialise it.</p>
<p><a href="https://gist.github.com/justinyoo/f6a451c44b34bcb62f28" target="_blank" rel="external">https://gist.github.com/justinyoo/f6a451c44b34bcb62f28</a></p>
<h3 id="YamlFilterItemCollection"><a href="#YamlFilterItemCollection" class="headerlink" title="YamlFilterItemCollection"></a><code>YamlFilterItemCollection</code></h3><p>If YAML is your preference, get <code>filter.yml</code> like:</p>
<p><a href="https://gist.github.com/justinyoo/aa10f921fca99495f13c" target="_blank" rel="external">https://gist.github.com/justinyoo/aa10f921fca99495f13c</a></p>
<p>And deserialise it. <a href="https://github.com/aaubry/YamlDotNet" target="_blank" rel="external"><code>YamlDotNet</code></a> makes your life easier for this operation.</p>
<p><a href="https://gist.github.com/justinyoo/9742709b60774a642a2d" target="_blank" rel="external">https://gist.github.com/justinyoo/9742709b60774a642a2d</a></p>
<p>All done! Regardless the setup file is <code>filter.xml</code>, <code>filter.json</code>, or <code>filter.yml</code> you can filter out entities only necessary. So, how to apply it? There’s only one step left. Let’s have a look.</p>
<h2 id="build-bat-and-CrmSvcUtil-exe-config"><a href="#build-bat-and-CrmSvcUtil-exe-config" class="headerlink" title="build.bat and CrmSvcUtil.exe.config"></a><code>build.bat</code> and <code>CrmSvcUtil.exe.config</code></h2><p>Firstly, <code>CrmSvcUtil.exe</code> needs its configuration file, <code>CrmSvcUtil.exe.config</code>. We can add <code>&amp;lt;appSettings&amp;gt;</code> node for configuration like:</p>
<p><a href="https://gist.github.com/justinyoo/362f7f974749cb717dbe" target="_blank" rel="external">https://gist.github.com/justinyoo/362f7f974749cb717dbe</a></p>
<p>They can be passed within the command prompt, if you like.</p>
<ol>
<li><code>language</code>: To define language to generate proxy file.</li>
<li><code>out</code>: To define the filename for generation. eg) <code>OrganisationService.cs</code></li>
<li><code>serviceContextName</code>: To define service context class inheriting <code>CrmOrganizationServiceContext</code>. eg) <code>OrganisationServiceContext</code></li>
<li><code>codeCustomization</code>: To point the assembly for filtering extension.</li>
<li><code>codeWriterFilter</code>: To point the assembly that contains the actual filtering logic.</li>
</ol>
<p>Once completed, create <code>build.bat</code> looking like:</p>
<p><a href="https://gist.github.com/justinyoo/21d97430acf43f15ba4e" target="_blank" rel="external">https://gist.github.com/justinyoo/21d97430acf43f15ba4e</a></p>
<p>Inside the batch file, you can setup the CRM service endpoint URL and namespace for output. Also you can ask the user manually type their username and password. Make sure that the password is <strong>NOT</strong> masked in this example, which is not secure.</p>
<p>Done! Run the <code>build.bat</code> and you’ll be able to see the <code>OrganisationService.cs</code> file generated. So, how can we apply this generated class? Let’s create a Web API app for test. There is a simple Web API app included in the sample code.</p>
<h2 id="Web-API-Application"><a href="#Web-API-Application" class="headerlink" title="Web API Application"></a>Web API Application</h2><p>The generated <code>OrganisationService.cs</code> has the <code>OrganisationServiceContext</code> class. As this is a <code>partial</code> class, we can extend this class by implementing a new interface, <code>IOrganisationServiceContext</code> for testing and DI purpose. Of course, you can directly use the contet class without it.</p>
<h3 id="IOrganisationServiceContext"><a href="#IOrganisationServiceContext" class="headerlink" title="IOrganisationServiceContext"></a><code>IOrganisationServiceContext</code></h3><p><a href="https://gist.github.com/justinyoo/be0622e49525baa59005" target="_blank" rel="external">https://gist.github.com/justinyoo/be0622e49525baa59005</a></p>
<p>In fact, the <code>CrmOrganizationServiceContext</code> class is very similar to the <code>DbContext</code> class, only <code>IQueryable&amp;lt;T&amp;gt;</code> properties need to be defined in the interface. Then implement it with another partial class of <code>OrganisationServiceContext</code>.</p>
<p><a href="https://gist.github.com/justinyoo/c24d288c53aa320c9601" target="_blank" rel="external">https://gist.github.com/justinyoo/c24d288c53aa320c9601</a></p>
<p>One of the reasons using the interface is to write mocking for test codes. Also it’s good for dependency injection with IoC containers. If you use <a href="http://autofac.org" target="_blank" rel="external"><code>Autofac</code></a>, for example, the following code snippet shows how to register dependencies.</p>
<p><a href="https://gist.github.com/justinyoo/1e6aba327beb60895a40" target="_blank" rel="external">https://gist.github.com/justinyoo/1e6aba327beb60895a40</a></p>
<p>Now, all setup. You can use <code>OrganisationServiceContext</code> as if you are using Entity Framework.</p>
<p><a href="https://gist.github.com/justinyoo/c9adc17279089057fea0" target="_blank" rel="external">https://gist.github.com/justinyoo/c9adc17279089057fea0</a></p>
<p>The result will look like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/12/crm-2015-filtering-01.png" alt=""></p>
<p>So far, we have implemented and applied CRM organisation service context by filtering selected entities with various types of setup files. With this, CRM integration for other applications will be much easier and faster. CRM 2015 also provides <a href="https://msdn.microsoft.com/dynamics/crm/webapipreview" target="_blank" rel="external">REST-basis Web API</a>. This is still at early stage but yet powerfull so will be discussed in another post sooner or later.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This is a cross-posting of &lt;a href=&quot;http://blog.kloud.com.au/2015/12/02/testable-entity-filtering-for-service-context-on-dyn
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="CrmSvcUtil.exe" scheme="http://devkimchi.com/tags/CrmSvcUtil-exe/"/>
    
      <category term="Dependency Injection" scheme="http://devkimchi.com/tags/Dependency-Injection/"/>
    
      <category term="Dynamics CRM" scheme="http://devkimchi.com/tags/Dynamics-CRM/"/>
    
      <category term="Dynamics CRM Online" scheme="http://devkimchi.com/tags/Dynamics-CRM-Online/"/>
    
      <category term="Filtering" scheme="http://devkimchi.com/tags/Filtering/"/>
    
      <category term="Testability" scheme="http://devkimchi.com/tags/Testability/"/>
    
  </entry>
  
  <entry>
    <title>Building SPA with Event Sourcing and CQRS Pattern</title>
    <link href="http://devkimchi.com/2015/11/17/building-spa-with-event-sourcing-and-cqrs-pattern/"/>
    <id>http://devkimchi.com/2015/11/17/building-spa-with-event-sourcing-and-cqrs-pattern/</id>
    <published>2015-11-17T08:53:59.000Z</published>
    <updated>2016-09-13T12:11:48.456Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p><strong>Acknowledgement</strong>: This is a cross-posting over <a href="http://blog.kloud.com.au/2015/11/16/building-applications-with-event-sourcing-and-cqrs-pattern" target="_blank" rel="external">Building Applications with Event Sourcing and CQRS Pattern</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud blog</a>.</p>
</blockquote>
<p>When we start building an application on cloud, like <a href="https://azure.microsoft.com" target="_blank" rel="external">Azure</a>, we should consider many factors. Those factors include flexibility, scalability, performance and so on. In order to satisfy those factors, components making up the application should be loosely coupled and ready for extension and change at any time. For those considerations, Microsoft has introduced <a href="https://msdn.microsoft.com/en-us/library/dn568099.aspx" target="_blank" rel="external">24 cloud design patterns</a>. Even though they are called as <strong>“Cloud Design Patterns”</strong>, they can be used just for application development anyway. In this post, I’m going to introduce <a href="https://msdn.microsoft.com/en-us/library/dn589792.aspx" target="_blank" rel="external">Event Sourcing Pattern</a> and <a href="https://msdn.microsoft.com/en-us/library/dn568103.aspx" target="_blank" rel="external">CQRS Pattern</a> and how they can be used in a single page application (SPA) like AngularJS application.</p>
<blockquote>
<p>The complete code sample can be found <a href="https://github.com/devkimchi/EventSourcing-CQRS-Sample" target="_blank" rel="external">here</a>.</p>
</blockquote>
<h2 id="Patterns-Overview"><a href="#Patterns-Overview" class="headerlink" title="Patterns Overview"></a>Patterns Overview</h2><p>I’m not going into too much details here to explain what Event Sourcing (ES) Pattern and CQRS Pattern are. According to articles linked above, both ES and CQRS easily get along with each other. AS the name itself says, CQRS separates commands from query &ndash; commands and query use different dataset and ES supports event stream for data store (commands), and materialisation and replaying (query). Let’s take a look at the diagram below.</p>
<p><img src="https://i-msdn.sec.s-msft.com/dynimg/IC709550.png" alt=""><br>[Image from: <a href="https://msdn.microsoft.com/en-us/library/dn589792.aspx" target="_blank" rel="external">https://msdn.microsoft.com/en-us/library/dn589792.aspx</a>]</p>
<p>This explains how ES and CQRS work together. Any individual input (or behaviour) from a user on the presentation layer (possibly Angular app in this post) is captured as an event and stored into event stream with timestamp. This storing action is <code>append-only</code>, ie events are only to be added. Therefore, the event stream becomes a <code>source of truth</code>, so all events captured and stored into the event stream can be replayed for query or materialised for transaction.</p>
<p>OK. Theory is enough. Let’s build an Angular app with Web API.</p>
<h2 id="Client-side-Implementation-for-Event-Triggering"><a href="#Client-side-Implementation-for-Event-Triggering" class="headerlink" title="Client-side Implementation for Event Triggering"></a>Client-side Implementation for Event Triggering</h2><p><img src="http://blob.devkimchi.com/devkimchiwp/2015/11/event-sourcing-cqrs.01.png" alt=""></p>
<p>There are three user input fields &ndash; <code>Title</code>, <code>Name</code> and <code>Email</code> &ndash; and the <code>Submit</code> button. Each field and button acts as an event. In this code sample, they are named as <code>SalutationChangedEvent</code>, <code>UsernameChangedEvent</code>, <code>EmailChangedEvent</code> and <code>UserCreatedEvent</code>. Those events are handled by event handlers at the Web API side. What the Angular app does is to capture the input values when they are being changed and clicked. This is a sample TypeScript code bits for the name field directive.</p>
<p><a href="https://gist.github.com/justinyoo/8296de50b364bc2800f6" target="_blank" rel="external">https://gist.github.com/justinyoo/8296de50b364bc2800f6</a></p>
<p>This HTML is a template used for the directive below. <code>ng-model</code> will capture the field value and the value will be sent to the server to store event stream.</p>
<p><a href="https://gist.github.com/justinyoo/de8284ca511aa72ccbc1" target="_blank" rel="external">https://gist.github.com/justinyoo/de8284ca511aa72ccbc1</a></p>
<p>Please bear in mind that, as this is written in <a href="http://typescriptlang.org" target="_blank" rel="external">TypeScript</a>, the coding style is slightly different from the original Angular 1.x way.</p>
<ol>
<li>The interface <code>IUserNameScope</code> defines <code>model</code> property and <code>change</code> function. This inherits <code>$scope</code>.</li>
<li>The interface is injected to both <code>link</code> and <code>controller</code> of the directive <code>UserName</code> that implements <code>ng.IDirective</code>.</li>
<li>A <code>link</code> function of the directive takes care of all DOM related ones.</li>
<li>The <code>link</code> function calls the function declared in <code>$scope</code> to send AJAX request to Web API.</li>
<li>A POST AJAX request is sent through <code>userNameFactory</code> to the server.</li>
<li>A response comes from the server as a <code>promise</code> format and the response is passed to <code>replayViewFactory</code> for replay.</li>
</ol>
<p>Both <code>Title</code> and <code>Email</code> fields work the same way as the <code>Name</code> field. Now, let’s have a look how the replay view section looks like.</p>
<p><a href="https://gist.github.com/justinyoo/62dc63c66bba06a01190" target="_blank" rel="external">https://gist.github.com/justinyoo/62dc63c66bba06a01190</a></p>
<p>This HTML template is used for the directive below. The following directive is only to replay responses.</p>
<p><a href="https://gist.github.com/justinyoo/d29265454f2201919c01" target="_blank" rel="external">https://gist.github.com/justinyoo/d29265454f2201919c01</a></p>
<p>As you can see, this directive only calls the <code>replayViewFactory.getReplayedView()</code> function to display what changes are. How do those events get comsumed at the server-side then? Let’s move onto the next look.</p>
<h2 id="Server-side-Implementation-for-Event-Processing"><a href="#Server-side-Implementation-for-Event-Processing" class="headerlink" title="Server-side Implementation for Event Processing"></a>Server-side Implementation for Event Processing</h2><p>The POST request has been sent through a designated endpoint like:</p>
<p><a href="https://gist.github.com/justinyoo/f6ebc4a218c24a7bcd1b" target="_blank" rel="external">https://gist.github.com/justinyoo/f6ebc4a218c24a7bcd1b</a></p>
<p>This request is captured in this Web API action:</p>
<p><a href="https://gist.github.com/justinyoo/b7e1cadfbcc2d7b32f6e" target="_blank" rel="external">https://gist.github.com/justinyoo/b7e1cadfbcc2d7b32f6e</a></p>
<p>The action in the controller merely calls the <code>this._service.ChangeUsernameAsync(request)</code> method. Not too excited. Let’s dig into the service layer then.</p>
<p><a href="https://gist.github.com/justinyoo/f443d32960e5ea36872c" target="_blank" rel="external">https://gist.github.com/justinyoo/f443d32960e5ea36872c</a></p>
<ol>
<li>Based on the type of the request passed, an appropriate request handler is selected.</li>
<li>The request handler converts the request into a corresponding event. In this code sample, the <code>UsernameChangeRequest</code> is converted to <code>UsernameChangedEvent</code> by the handler.</li>
<li>An event processor takes the event and process it.</li>
</ol>
<p>A question may arise here. How does request handler selection work? Each request handler implements <code>IRequestHandler</code> and it defines two methods:</p>
<p><a href="https://gist.github.com/justinyoo/5930098dfe9b8d5ed77b" target="_blank" rel="external">https://gist.github.com/justinyoo/5930098dfe9b8d5ed77b</a></p>
<p>Therefore, you can create as many request handlers as you like, and register them into your IoC container (using <a href="http://autofac.org" target="_blank" rel="external">Autofac</a> for example) like:</p>
<p><a href="https://gist.github.com/justinyoo/fc454b59b8879b0d37d1" target="_blank" rel="external">https://gist.github.com/justinyoo/fc454b59b8879b0d37d1</a></p>
<p>In the sample code used here registers five request handlers. If your business logic is way far complex and require many request handlers, you might need to consider moduling those request handlers automatic registration. I’ll discuss this in another post soon. Another question may arise again. How does the event processor work? Let’s have a look. Here’s the event processor:</p>
<p><a href="https://gist.github.com/justinyoo/31ec05821f2f60df7d11" target="_blank" rel="external">https://gist.github.com/justinyoo/31ec05821f2f60df7d11</a></p>
<p>This is quite similar to the <code>EventStreamService.ChangeUsernameAsync()</code>. First of all, find all event handlers that can handle the event. Then those selected event handlers process the event as all event handlers implements <code>IEventHandler</code> interface:</p>
<p><a href="https://gist.github.com/justinyoo/80998cb0367642459d78" target="_blank" rel="external">https://gist.github.com/justinyoo/80998cb0367642459d78</a></p>
<p>To wrap up,</p>
<ol>
<li>A user action is captured at a client-side and passed to a server-side as a request.</li>
<li>The user action request is converted to an event by request handlers.</li>
<li>The event is then processed and stored into event stream by event handlers.</li>
</ol>
<p>Of course, I’m not arguing this is the perfect example for event processing. However, at least, it’s working and open for extension, which is good.</p>
<h2 id="Replaying-Events"><a href="#Replaying-Events" class="headerlink" title="Replaying Events"></a>Replaying Events</h2><p>Now, all events are raised and stored into event stream with timestamp. Event stream becomes a <code>source of truth</code>. Therefore, if we want to populate a user’s data against a particular time period, as long as we provide timestamp, we’re able to load the data without impacting on the actual data store. If you run the code sample on your local and make some user input change, you’ll actually be able to see the replayed view.</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/11/event-sourcing-cqrs.02.png" alt=""></p>
<p>Now, let’s store the user data into the <strong>real</strong> data store by event materialisation.</p>
<h2 id="Materialising-Events"><a href="#Materialising-Events" class="headerlink" title="Materialising Events"></a>Materialising Events</h2><p>When you hit the <code>Submit</code> button, the server-side replays all events from the event stream with the current timestamp for materialisation. Then the materialised view is stored into the <code>User</code> table. As this is considered as another event, another event, <code>UserCreatedEvent</code> is created and processed by <code>UserCreatedEventHandler</code>. Unlike other event handlers, it does not only use the event stream repository, but also use the user repository.</p>
<p><a href="https://gist.github.com/justinyoo/fed0b4ab1bede237f941" target="_blank" rel="external">https://gist.github.com/justinyoo/fed0b4ab1bede237f941</a></p>
<p>In other words, the event itself is stored into the event stream and a user data from the event is stored into the user repository. Once stored, you will be able to find on the screen.</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/11/event-sourcing-cqrs.03.png" alt=""></p>
<p>Please note that, if you change <code>Title</code>, <code>Name</code>, or <code>Email</code> but not yet click the <code>Submit</code> button, you’ll find some difference like the following screen:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/11/event-sourcing-cqrs.04.png" alt=""></p>
<p>So far, we’ve briefly discussed both ES pattern and CQRS pattern with a simple Angular - Web API app. How did you find it? Wouldn’t it be nice for your next application development? Make sure one thing. Applying those patterns might bring overly complex architecture into your application as there are many abstraction layers involved. If your application is relatively simple or small, you don’t have to consider those patterns. However, your application is growing and becomes heavier and complex, then it’s time to consider getting those patterns implemented for your application.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Acknowledgement&lt;/strong&gt;: This is a cross-posting over &lt;a href=&quot;http://blog.kloud.com.au/2015/11/16/building-applica
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="AngularJS" scheme="http://devkimchi.com/tags/AngularJS/"/>
    
      <category term="Cloud Design Pattern" scheme="http://devkimchi.com/tags/Cloud-Design-Pattern/"/>
    
      <category term="CQRS Pattern" scheme="http://devkimchi.com/tags/CQRS-Pattern/"/>
    
      <category term="Event Sourcing Pattern" scheme="http://devkimchi.com/tags/Event-Sourcing-Pattern/"/>
    
      <category term="TypeScript" scheme="http://devkimchi.com/tags/TypeScript/"/>
    
      <category term="Web API" scheme="http://devkimchi.com/tags/Web-API/"/>
    
  </entry>
  
  <entry>
    <title>Creating Service Contract with AutoRest, Swagger and HAL</title>
    <link href="http://devkimchi.com/2015/10/28/creating-service-contract-with-autorest-swagger-and-hal/"/>
    <id>http://devkimchi.com/2015/10/28/creating-service-contract-with-autorest-swagger-and-hal/</id>
    <published>2015-10-28T05:00:16.000Z</published>
    <updated>2016-09-13T12:11:48.458Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>Acknowledgement: This is a cross-posting over <a href="http://blog.kloud.com.au/2015/10/26/creating-service-contract-with-autorest-swagger-and-hal" target="_blank" rel="external">Creating Service Contract with AutoRest, Swagger and HAL</a> at <a href="http://blog.kloud.com.au" target="_blank" rel="external">Kloud blog</a>.</p>
</blockquote>
<p>According to <a href="http://martinfowler.com/articles/richardsonMaturityModel.html" target="_blank" rel="external">Richardson Maturity Model</a>, REST API level 3 should provide hypermedia within responses as metadata, so that users can easily navigate to other resources. This is particularly important if <a href="http://martinfowler.com/articles/microservices.html" target="_blank" rel="external">Microservices architecture (MSA)</a> is considered for your service or application. Because MSA is a collection of small REST API services, each API server should provide complete set of documents or manuals for others to consume it properly. In order to provide document automation, <a href="http://swagger.io" target="_blank" rel="external">Swagger</a> is one of the best choices, and <a href="http://stateless.co/hal_specification.html" target="_blank" rel="external">HAL</a>, in order to provide hypermedia within the response, is also yet another option. Of course, consuming those REST API at client applications is also important. In this case, <a href="https://github.com/Azure/autorest" target="_blank" rel="external">AutoRest</a> can give great benefits for your development. In this post, I’ll discuss HAL, Swagger and AutoRest with some demo codes.</p>
<p>Demo codes can be found at:</p>
<ul>
<li><a href="https://github.com/devkimchi/HAL-Swagger-Sample" target="_blank" rel="external">https://github.com/devkimchi/HAL-Swagger-Sample</a></li>
<li><a href="https://github.com/devkimchi/TypeScript-WebApi-Sample" target="_blank" rel="external">https://github.com/devkimchi/TypeScript-WebApi-Sample</a></li>
</ul>
<h2 id="Integrating-HAL"><a href="#Integrating-HAL" class="headerlink" title="Integrating HAL"></a>Integrating HAL</h2><p>HAL (Hypertext Application Language) has been suggested by <a href="http://stateless.co" target="_blank" rel="external">Mike Kelly</a>. Its formal specification can be found at this <a href="http://tools.ietf.org/html/draft-kelly-json-hal" target="_blank" rel="external">IETF draft</a>. Generally speaking, many REST API services are well structured. They don’t just only return data in the response, but also include various metadata for reference purpose, in their <em>own</em> way. HAL offers a standardised way of including hyperlinks into those responses. Here’s an example</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-txt" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-txt</a></p>
<p>If you send a request with the URL above, the expecting response will look like:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-json" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-json</a></p>
<p>However, if HAL is applied, the response will look like:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-hal-json" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-hal-json</a></p>
<p>Let’s see another example returning a collection.</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-collection-txt" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-collection-txt</a></p>
<p>The request will expect reaponse like:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-collection-json" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-collection-json</a></p>
<p>If HAL is applied, the response will look like:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-collection-hal-json" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-get-product-collection-hal-json</a></p>
<p>Can you see differences? HAL applied responses contain much richer data that can easily navigate to other resources.</p>
<p>OK, theory is done. Let’s implement HAL on your API. First of all, assuming you’ve got an existing Web API app containing models of <code>Product</code> and <code>ProductCollection</code> looking like:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-product-product-collection-model-cs" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-product-product-collection-model-cs</a></p>
<p>There are many HAL implementations on our <a href="https://nuget.org" target="_blank" rel="external">NuGet</a>. For now, I’m going to use <a href="https://www.nuget.org/packages/WebApi.Hal" target="_blank" rel="external">WebApi.Hal</a>. Once installed, you can modify those models with this way, by minimising impacts on the existing application:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-product-product-collection-model-hal-cs" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-product-product-collection-model-hal-cs</a></p>
<p>Then, register HAL into your <code>Global.asax.cs</code> or <code>Startup.cs</code>:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-hal-config-cs" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-hal-config-cs</a></p>
<p>That’s it! Too simple? Here’s the magic inside the <code>Representation</code> class. It has the public <code>Links</code> property that takes care of all hypertext links. All we need after the HAL implementation is to add appropriate links to each instance, manually or automatically. Here’s a way to include hyperlinks manually within a controller level:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-product-api-controller-hal-cs" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-product-api-controller-hal-cs</a></p>
<p>Once it’s done, build it and check the API response. Then you’ll see the result including those HAL links like above. Now, let’s move to the next part, Swagger.</p>
<h2 id="Integrating-Swagger"><a href="#Integrating-Swagger" class="headerlink" title="Integrating Swagger"></a>Integrating Swagger</h2><p>According to <a href="http://swagger.io" target="_blank" rel="external">Swagger website</a>, Swagger provides a standard, languae-independent interface to REST API so that both humans and computers can easily find and understand the API structure without reading source codes or documents. There are several other alternatives like <a href="http://raml.org" target="_blank" rel="external">RAML</a> or <a href="https://apiblueprint.org" target="_blank" rel="external">API Blueprint</a>, so it’s up to you which one shoul you choose.</p>
<p><a href="https://github.com/domaindrivendev/Swashbuckle" target="_blank" rel="external">Swashbuckle</a> is one of C# implementations of Swagger. It’s easy to use and virtually zero configuration is required for the basic usage. Let’s install Swashbuckle into your project. Once installed, it also adds another file, <code>SwaggerConfig.cs</code> under the <code>App_Start</code> directory. You can directly use it or do some modification for your application. Let’s have a look.</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-swagger-config-before-cs" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-swagger-config-before-cs</a></p>
<p>When you open <code>SwaggerConfig.cs</code> file, it looks like above. In order for you to have more control on it, comment out the first line, <code>[assembly: ...]</code> and make the <code>Register()</code> method to be an extension method:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-swagger-config-after-cs" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-swagger-config-after-cs</a></p>
<p>Then, put the following like into either your <code>Global.asax.cs</code> or <code>Startup.cs</code> for registration:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-swagger-config-cs" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-swagger-config-cs</a></p>
<p>That’s all. Build and run your app, type URL like <code>http://my.api.service/swagger</code> and you will see the Swagger UI screen like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/10/swagger-01.png" alt=""></p>
<p>What you need to notice is the JSON schema URL in the picture above. When you type the URL from <a href="https://chrome.google.com/webstore/detail/postman/fhbjgbiflinjbdggehcddcbncdddomop" target="_blank" rel="external">Postman</a>, it will look like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/10/swagger-02.png" alt=""></p>
<p>This is basically a JSON schema file and pretty much equivalent to WSDL from SOAP. With terms of WCF, it contains both service contract and data contract so, with this schema, your client applications can access to the API and consume it. There’s no obstacle for it.</p>
<p>So far, we’ve implemented both HAL and Swagger on your REST API server. How can we then consume those APIs on your clients like web app or mobile app? Let’s move onto the next section for this.</p>
<h2 id="Deserialising-Swagger-JSON-schema-with-AutoRest"><a href="#Deserialising-Swagger-JSON-schema-with-AutoRest" class="headerlink" title="Deserialising Swagger JSON schema with AutoRest"></a>Deserialising Swagger JSON schema with AutoRest</h2><p>Once Swagger JSON schema is generated, your client apps should be able to consume it with minised efforts. <a href="https://github.com/Azure/autorest" target="_blank" rel="external">AutoRest</a> can bring great benefits to your client apps. It automatically generates both service contracts and data contracts pointing to your REST APIs using Swagger JSON schema. Currently, AutoRest supports C#, Java, Node.js and Ruby and the number of languages gets gradually expanded.</p>
<p>Here’s an ASP.NET MVC app. Within the app, assuming there’s a folder, <code>Proxies</code>. Swagger JSON schema file is then placed into that folder with name of <code>swagger.json</code>. Then install <a href="https://www.nuget.org/packages/AutoRest" target="_blank" rel="external">AutoRest</a> CLI app and <a href="https://www.nuget.org/packages/Microsoft.Rest.ClientRuntime" target="_blank" rel="external">runtime library</a> from NuGet. In order to auto-generate client libraries, try the following command on your Command Prompt:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-build-bat" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-build-bat</a></p>
<p>What does the command line mean? Here’s the brief explanation:</p>
<ol>
<li>Run AutoRest.exe</li>
<li>Input JSON schema name is <code>swagger.json</code></li>
<li>The namespace for auto-generated files is <code>HalSwaggerSample.WebApp.Proxies</code></li>
<li>Store auto-generated files into <code>Proxies</code></li>
<li>Set output file type as C#</li>
</ol>
<p>After the generation, you will be able to see bunch of files have been stored into the <code>Proxies</code> folder. The most important file is <code>HalSwaggerSampleHalApiApp.cs</code>. Of course, the file name (or class name) will be different from yours. It provides the service endpoint and service contract information. It also contains the corresponding interface, <code>IHalSwaggerSampleHalApiApp</code>, so this service contract is testable, mockable and injectable. Therefore, your controller/action can be written like:</p>
<p><a href="https://gist.github.com/justinyoo/833c78c436948493bf87#file-product-mvc-controller-cs" target="_blank" rel="external">https://gist.github.com/justinyoo/833c78c436948493bf87#file-product-mvc-controller-cs</a></p>
<p>Therefore, the result screen will look like:</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/10/swagger-04.png" alt=""></p>
<p>Did you find that can’t be easier?</p>
<p>We’ve so far had a look at HAL, Swagger and AutoRest. Both HAL and Swagger are to design your REST API to be more discoverable, readable and maintainable and make client apps build their access point much easier with tools like AutoRest. How about implementing those into your Web API, if you’re considering MSA? It’s all yours.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Acknowledgement: This is a cross-posting over &lt;a href=&quot;http://blog.kloud.com.au/2015/10/26/creating-service-contract-with-au
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="AutoRest" scheme="http://devkimchi.com/tags/AutoRest/"/>
    
      <category term="HAL" scheme="http://devkimchi.com/tags/HAL/"/>
    
      <category term="REST API" scheme="http://devkimchi.com/tags/REST-API/"/>
    
      <category term="Swagger" scheme="http://devkimchi.com/tags/Swagger/"/>
    
      <category term="Swashbuckle" scheme="http://devkimchi.com/tags/Swashbuckle/"/>
    
  </entry>
  
  <entry>
    <title>Create BizTalk Groups and Accounts using PowerShell</title>
    <link href="http://devkimchi.com/2015/08/31/create-biztalk-groups-and-accounts-using-powershell/"/>
    <id>http://devkimchi.com/2015/08/31/create-biztalk-groups-and-accounts-using-powershell/</id>
    <published>2015-08-31T01:28:38.000Z</published>
    <updated>2016-09-13T12:11:48.453Z</updated>
    
    <content type="html"><![CDATA[<div class="posts"><article class="post">You could find this article on TechNet gallery as well <a href="https://gallery.technet.microsoft.com/Create-BizTalk-Groups-and-16b2fbe8" target="_blank" rel="external">here</a><br><br>### 1. Purpose<br><br>One of the task that we need to do in all our new BizTalk environment over and over again is creating BizTalk security groups and service accounts. Although this will be handled by Domain Administrator from customer’s organization, BizTalk admin user is supposed to provide all the detail required prior to BizTalk installation. You could hand this script along with spreadsheet <a href="http://ahkim.com/wp-content/uploads/2015/08/25/BizTalk-Groups-and-Accounts.xlsx" target="_blank" rel="external">here</a> and make communication between yourself and Domain administrator easier.<br><br>### 2. Assumptions<br><br>*   BizTalk security groups and service accounts will be created in following Organization Unit by default.<br><img src="http://i.imgur.com/Asgmynm.png" alt=""><br><br>Target OU path is to be generated in following format.<br><div class="highlight"><br><br>    OU={something},OU={something-branch},OU={Organization},DC={subdomain},DC={domain},DC={TopLevelDomain}<br>    <code>&lt;/pre&gt;
    &lt;/div&gt;
    Sample domain doesn&#39;t have a subdomain. Therefore, target path for the example will be
    &lt;div class=&quot;highlight&quot;&gt;
    &lt;pre&gt;</code>OU=BizTalk,OU=DEV,OU=Service Accounts,DC=aklab,DC=com<br><br></div>

<ul>
<li>Service Accounts will be created in the form of svc-BTS-{Env}-{Role}</li>
<li>Security groups will be created in the form of BTS-{Env} {Group name}</li>
</ul>
<h3 id="3-Features"><a href="#3-Features" class="headerlink" title="3. Features"></a>3. Features</h3><p>Here is the list of what this script does</p>
<p><img src="http://i.imgur.com/UXA4Qcx.png" alt=""></p>
<h4 id="3-1-Create-BizTalk-admin-user-account"><a href="#3-1-Create-BizTalk-admin-user-account" class="headerlink" title="3.1. Create BizTalk admin user account"></a>3.1. Create BizTalk admin user account</h4><p>At least one BizTalk admin user account(most likely for yourself) is necessary to install and configure BizTalk farms but probably already create in AD. Therefore, creation of this is commented out by default. This account should become a local administrator on BizTalk servers at least for installation and configuration period. In case customer’s organization has a security concern for allowing user account to be a local administrator, you could uncomment and create this account, leverage as a dedicated setup account and remove it later.</p>
<p><img src="http://i.imgur.com/DfNauR1.png" alt=""></p>
<h4 id="3-2-Add-BizTalk-admin-user-account-into-a-Local-Administrator-group-on-BizTalk-server"><a href="#3-2-Add-BizTalk-admin-user-account-into-a-Local-Administrator-group-on-BizTalk-server" class="headerlink" title="3.2. Add BizTalk admin user account into a Local Administrator group on BizTalk server"></a>3.2. Add BizTalk admin user account into a Local Administrator group on BizTalk server</h4><p>BizTalk admin user will be added into Local Administrator group on BizTalk server.</p>
<p><img src="http://i.imgur.com/k6ynRsF.png" alt=""></p>
<h4 id="3-3-Create-security-groups-and-service-accounts"><a href="#3-3-Create-security-groups-and-service-accounts" class="headerlink" title="3.3. Create security groups and service accounts"></a>3.3. Create security groups and service accounts</h4><p><img src="http://i.imgur.com/yyUOR5D.png" alt=""></p>
<h4 id="3-4-Add-service-accounts-into-appropriate-BizTalk-security-groups"><a href="#3-4-Add-service-accounts-into-appropriate-BizTalk-security-groups" class="headerlink" title="3.4. Add service accounts into appropriate BizTalk security groups"></a>3.4. Add service accounts into appropriate BizTalk security groups</h4><p><img src="http://i.imgur.com/WRRCiwN.png" alt=""></p>
<h4 id="3-5-Add-Domain-Admins-group-into-every-BizTalk-security-groups"><a href="#3-5-Add-Domain-Admins-group-into-every-BizTalk-security-groups" class="headerlink" title="3.5. Add Domain Admins group into every BizTalk security groups"></a>3.5. Add Domain Admins group into every BizTalk security groups</h4><p><img src="http://i.imgur.com/sImygPv.png" alt=""></p>
<h3 id="4-Spreadsheet"><a href="#4-Spreadsheet" class="headerlink" title="4. Spreadsheet"></a>4. Spreadsheet</h3><p>Spreadsheet <a href="http://ahkim.com/wp-content/uploads/2015/08/25/BizTalk-Groups-and-Accounts.xlsx" target="_blank" rel="external">here</a> gives instant visibility of what domain groups and accounts will be created. Ask Domain Administrator to update the password section and return it to you so that you could build the BizTalk farms.</p>
<p><img src="http://i.imgur.com/jgSxNZr.png" alt=""></p>
<h3 id="5-Script"><a href="#5-Script" class="headerlink" title="5. Script"></a>5. Script</h3><p>You can download the script <a href="http://ahkim.com/wp-content/uploads/2015/08/25/Create-BizTalkGroupsAndAccounts.ps1" target="_blank" rel="external">here</a>. I would really appreciate your feedback and more than welcome to help if you find any issue. Please feel free to leave a comment or contact me.</p>
<p><pre class="lang:default decode:true " title="Create-BizTalkGroupsAndAccounts.ps1">&lt;#<br>    .SYNOPSIS</pre></p>
<pre><code>.DESCRIPTION
This script is written to help domain administrator to create BizTalk security groups and service accounts
with naming standard following in mind. Using this, you could segregate environments from one another within
the same domain. 

Service Accounts will be created in the form of svc-BTS-{Env}-{Role}

e.g. 
- svc-BTS-DEV-Host
- svc-BTS-DEV-IsHost
- svc-BTS-DEV-RuleEn
- svc-BTS-DEV-SSO

Security groups will be created in the form of BTS-{Env} {Group name}

e.g.
- BTS-DEV Admins
- BTS-DEV SSO Admins
- BTS-DEV Affiliate SSO Admins
- BTS-DEV InProcess Hosts
- BTS-DEV Isolated Hosts
- BTS-DEV Operaters
- BTS-DEV B2B Operators
- BTS-DEV BAM Portal Users

Step 1)

BizTalk security groups and services accounts will be created in following Organization Unit by default. 
You would need to adjust the script for your environment accordingly. 

Root
    Service Accounts
        {Env}
            BizTalk

Creating above Organization Unit in PowerShell is also included but commented out by default. 

Step 2)

Regions called &quot;Set environment variables&quot; and &quot;Create/Update BizTalk Admin User Account and add to local 
Administrators group on BizTalk Server&quot; includes configurable values. Please update. 

Step 3)

Passwords for service accounts are default to &quot;P@ssword&quot;. Please update these based on security policy and
also update provided excel file with changed password detail and give back to BizTalk Admin User as he or 
she would need this to install and configure BizTalk going forward.

Step 4)

Open Administrative PowerShell console, and set the execution policy to Unrestricted.  

Set-ExecutionPolicy Unrestricted

Step 5)

Run Create-BizTalkGroupsAndAccounts.ps1

.EXAMPLE
Create-BizTalkGroupsAndAccounts

.NOTES
Filename:     Create-BizTalkGroupsAndAccounts.ps1

Maintenance History
Name               Date         Version     C/R     Description        
----------------------------------------------------------------------------------
Aaron Kim          2015-08-25   1.0.0               Created 
</code></pre><p>#&gt;</p>
<p>##———————————————————————–</p>
<h2 id="Function-Main"><a href="#Function-Main" class="headerlink" title="Function: Main"></a>Function: Main</h2><h2 id="Purpose-Main-logic"><a href="#Purpose-Main-logic" class="headerlink" title="Purpose: Main logic"></a>Purpose: Main logic</h2><p>##———————————————————————–<br>Function Main<br>{</p>
<pre><code>#region Set environment variables

$Env = &quot;DEV&quot;
$SubDomain = &quot;&quot;
$Domain = &quot;aklab&quot;
$TopLevelDomain = &quot;com&quot;

# Path to create the BizTalk groups and service accounts. e.g. OU={something},OU={something-branch},OU={Organization},DC={subdomain},DC={domain},DC={TopLevelDomain}
#$BtsOuPath = &quot;OU=BizTalk,OU=$Env,OU=Service Accounts,DC=$Subdomain,DC=$Domain,DC=$TopLevelDomain&quot; 
$BtsOuPath = &quot;OU=BizTalk,OU=$Env,OU=Service Accounts,DC=$Domain,DC=$TopLevelDomain&quot; 
# This Path must exist. If you would like to create a path in sample, you could use following command. 
#NEW-ADOrganizationalUnit “Service Accounts”
#NEW-ADOrganizationalUnit $Env –path “OU=Service Accounts,DC=$Domain,DC=$TopLevelDomain”
#NEW-ADOrganizationalUnit BizTalk –path “OU=$Env,OU=Service Accounts,DC=$Domain,DC=$TopLevelDomain”

# Please update with domain administrator&apos;s user account or group
$DomainAdmin = &quot;Domain Admins&quot;

# Service Accounts and Passwords
$BTSHost = &quot;svc-BTS-$Env-Host&quot;
$BTSIsolatedHost = &quot;svc-BTS-$Env-IsHost&quot;
$BTSRuleEn = &quot;svc-BTS-$Env-RuleEn&quot;
$BTSSSOSvc = &quot;svc-BTS-$Env-SSO&quot;

# Convert the plain text passwords
$BTSHostPassword = ConvertTo-SecureString &quot;P@ssword&quot; -AsPlainText -Force
$BTSIsoHostPassword = ConvertTo-SecureString &quot;P@ssword&quot; -AsPlainText -Force
$BTSRuleEnPassword = ConvertTo-SecureString &quot;P@ssword&quot; -AsPlainText -Force
$BTSSSOSvcPassword = ConvertTo-SecureString &quot;P@ssword&quot; -AsPlainText -Force

#endregion

#region Create/Update BizTalk Admin User Account and add to local Administrators group on BizTalk Server 

# BizTalk Admin User account - This is a user account for someone who will install and configure BizTalk farm. 
# Most likely, at least user account must have been already created. In that case, update following line and comment out account creation part in this region. 
$BtsAdmin = $Env+&quot;BTSAdm&quot;

# Path where to create the BizTalk Admin User e.g. CN=Users,DC={subdomain},DC={domain},DC={TopLevelDomain}
#$AdminOuPath = &quot;CN=Users,DC=$SubDomain,DC=$Domain,DC=$TopLevelDomain&quot;
$AdminOuPath = &quot;CN=Users,DC=$Domain,DC=$TopLevelDomain&quot;

# Convert the plain text passwords
$BtsAdminPassword = ConvertTo-SecureString &quot;P@ssword&quot; -AsPlainText -Force
# Comment out following two in case BizTalk Admin user account is already created. 
# As this is a user account not a service account, allowed password to expire and let user to change the password at logon. Please update according to security policy. 
New-ADUser -SamAccountName $BtsAdmin -AccountPassword $BtsAdminPassword -name $BtsAdmin -enabled $true -PasswordNeverExpires $false -CannotChangePassword $false -ChangePasswordAtLogon $true -Path $AdminOuPath
Write-Host &quot;User account $BtsAdmin was successfully created&quot; -Fore DarkGreen

# BizTalk Admin User account should be a member of local Administrators group on BizTalk Server. 
# Update computer name accordingly and add more lines if there is more than 1 BizTalk Server.
$computer1 = &quot;AKBTS2k13R2&quot;
#Add-DomainUserToLocalGroup -computer $computer1 -group Administrators -domain $Subdomain.$Domain.$TopLevelDomain -user $BtsAdmin
Add-DomainUserToLocalGroup -computer $computer1 -group Administrators -domain $Domain&quot;.&quot;$TopLevelDomain -user $BtsAdmin
Write-Host &quot;User account $BtsAdmin was successfully added into Local Administrators group of $computer1&quot; -Fore DarkGreen
#endregion

#region Create Security Groups

$BTSAdminsDesc = &quot;Administrators who have the least privileges necessary to perform administrative tasks&quot;
$SSOAdminsDesc = &quot;Administrators of the Enterprise Single Sign-On (SSO) service&quot;
$SSOAffAdminsDesc = &quot;Administrators of certain SSO affiliate applications&quot;
$BTSOpsDesc = &quot;Operators who Have a low privilege role with access only to monitoring and troubleshooting actions&quot;
$BTSInProessHostsDesc = &quot;In-Process BizTalk Host Group&quot;
$BTSIsolatedHostsDesc = &quot;Isolated BizTalk Host Group&quot;
$BTSB2BOpsDesc = &quot;Operators to perform all Party management operation&quot;
$BAMPortalUsersDesc = &quot;Users who have access to BAM Portal Web site&quot;

New-ADGroup -Name &quot;BTS-$Env Admins&quot; -GroupCategory Security -GroupScope Global -DisplayName &quot;BTS-$Env Admins&quot; -Path $BtsOuPath -Description $BTSAdminsDesc
New-ADGroup -Name &quot;BTS-$Env SSO Admins&quot; -GroupCategory Security -GroupScope Global -DisplayName &quot;BTS-$Env SSO Admins&quot; -Path $BtsOuPath -Description $SSOAdminsDesc
New-ADGroup -Name &quot;BTS-$Env Affiliate SSO Admins&quot; -GroupCategory Security -GroupScope Global -DisplayName &quot;BTS-$Env Affiliate SSO Admins&quot; -Path $BtsOuPath -Description $SSOAffAdminsDesc
New-ADGroup -Name &quot;BTS-$Env Operaters&quot; -GroupCategory Security -GroupScope Global -DisplayName &quot;BTS-$Env Operaters&quot; -Path $BtsOuPath -Description $BTSOpsDesc
New-ADGroup -Name &quot;BTS-$Env InProcess Hosts&quot; -GroupCategory Security -GroupScope Global -DisplayName &quot;BTS-$Env InProcess Hosts&quot; -Path $BtsOuPath -Description $BTSInProessHostsDesc
New-ADGroup -Name &quot;BTS-$Env Isolated Hosts&quot; -GroupCategory Security -GroupScope Global -DisplayName &quot;BTS-$Env Isolated Hosts&quot; -Path $BtsOuPath -Description $BTSIsolatedHostsDesc
New-ADGroup -Name &quot;BTS-$Env B2B Operators&quot; -GroupCategory Security -GroupScope Global -DisplayName &quot;BTS-$Env B2B Operators&quot; -Path $BtsOuPath -Description $BTSB2BOpsDesc
# In case BAM Portal to be used
New-ADGroup -Name &quot;BTS-$Env BAM Portal Users&quot; -GroupCategory Security -GroupScope Global -DisplayName &quot;BTS-$Env BAM Portal Users&quot; -Path $BtsOuPath -Description $BAMPortalUsersDesc
Write-Host &quot;Security groups were successfully created in AD&quot; -Fore DarkGreen
#endregion

#region Create Service Accounts
# As these are service accounts, password expiration is not recommended which can cause serious disruption of service. 
New-ADUser -SamAccountName $BTSHost -AccountPassword $BTSHostPassword -name $BTSHost -enabled $true -PasswordNeverExpires $true -CannotChangePassword $true -ChangePasswordAtLogon $false -Path $BtsOuPath
New-ADUser -SamAccountName $BTSIsolatedHost -AccountPassword $BTSIsoHostPassword -name $BTSIsolatedHost -enabled $true -PasswordNeverExpires $true -CannotChangePassword $true -ChangePasswordAtLogon $false -Path $BtsOuPath
New-ADUser -SamAccountName $BTSRuleEn -AccountPassword $BTSRuleEnPassword -name $BTSRuleEn -enabled $true -PasswordNeverExpires $true -CannotChangePassword $true -ChangePasswordAtLogon $false -Path $BtsOuPath
New-ADUser -SamAccountName $BTSSSOSvc -AccountPassword $BTSSSOSvcPassword -name $BTSSSOSvc -enabled $true -PasswordNeverExpires $true -CannotChangePassword $true -ChangePasswordAtLogon $false -Path $BtsOuPath
Write-Host &quot;Service Accounts were successfully created in AD&quot; -Fore DarkGreen

#endregion

#region Add accounts to right security groups

# Add BizTalk Admin User account to BizTalk Administrators Group
Add-ADPrincipalGroupMembership -Identity $BtsAdmin -MemberOf &quot;BTS-$Env Admins&quot; 
# Add Service Accounts to belonging BizTalk groups
Add-ADPrincipalGroupMembership -Identity $BTSSSOSvc -MemberOf &quot;BTS-$Env SSO Admins&quot;
Add-ADPrincipalGroupMembership -Identity &quot;BTS-$Env Admins&quot; -MemberOf &quot;BTS-$Env SSO Admins&quot;
Add-ADPrincipalGroupMembership -Identity &quot;BTS-$Env Admins&quot; -MemberOf &quot;BTS-$Env Affiliate SSO Admins&quot;
Add-ADPrincipalGroupMembership -Identity $BTSHost -MemberOf &quot;BTS-$Env InProcess Hosts&quot;
Add-ADPrincipalGroupMembership -Identity $BTSIsolatedHost -MemberOf &quot;BTS-$Env Isolated Hosts&quot;
Add-ADPrincipalGroupMembership -Identity &quot;BTS-$Env Admins&quot; -MemberOf &quot;BTS-$Env BAM Portal Users&quot;
Write-Host &quot;Service Accounts were successfully added into BizTalk Security Groups&quot; -Fore DarkGreen

# Add the domain admin to all groups
Add-ADPrincipalGroupMembership -Identity $DomainAdmin -MemberOf &quot;BTS-$Env Admins&quot;
Add-ADPrincipalGroupMembership -Identity $DomainAdmin -MemberOf &quot;BTS-$Env SSO Admins&quot;
Add-ADPrincipalGroupMembership -Identity $DomainAdmin -MemberOf &quot;BTS-$Env Affiliate SSO Admins&quot;
Add-ADPrincipalGroupMembership -Identity $DomainAdmin -MemberOf &quot;BTS-$Env InProcess Hosts&quot;
Add-ADPrincipalGroupMembership -Identity $DomainAdmin -MemberOf &quot;BTS-$Env Isolated Hosts&quot;
Add-ADPrincipalGroupMembership -Identity $DomainAdmin -MemberOf &quot;BTS-$Env BAM Portal Users&quot;
Write-Host &quot;$DomainAdmin is successfully added into every BizTalk Security Group&quot; -Fore DarkGreen

#endregion
</code></pre><p>}</p>
<p>##———————————————————————–</p>
<h2 id="Function-Add-DomainUserToLocalGroup"><a href="#Function-Add-DomainUserToLocalGroup" class="headerlink" title="Function: Add-DomainUserToLocalGroup"></a>Function: Add-DomainUserToLocalGroup</h2><h2 id="Purpose-Remotely-add-domain-user-to-local-group-on-a-specified-computer"><a href="#Purpose-Remotely-add-domain-user-to-local-group-on-a-specified-computer" class="headerlink" title="Purpose: Remotely add domain user to local group on a specified computer"></a>Purpose: Remotely add domain user to local group on a specified computer</h2><p>##———————————————————————–<br>Function Add-DomainUserToLocalGroup<br>{<br>    [cmdletBinding()]<br>    Param(<br>        [Parameter(Mandatory=$True)]<br>        [string]$computer,<br>        [Parameter(Mandatory=$True)]<br>        [string]$group,<br>        [Parameter(Mandatory=$True)]<br>        [string]$domain,<br>        [Parameter(Mandatory=$True)]<br>        [string]$user<br>    ) </p>
<pre><code>$de = [ADSI]&quot;WinNT://$computer/$Group,group&quot; 
$de.psbase.Invoke(&quot;Add&quot;,([ADSI]&quot;WinNT://$domain/$user&quot;).path) 
</code></pre><p>}</p>
<p>Main<br>&nbsp;</p>
<div class="highlight"></div><br></article></div>

<div class="pagination"></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;posts&quot;&gt;&lt;article class=&quot;post&quot;&gt;You could find this article on TechNet gallery as well &lt;a href=&quot;https://gallery.technet.microsoft.c
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="BizTalk" scheme="http://devkimchi.com/tags/BizTalk/"/>
    
      <category term="PowerShell" scheme="http://devkimchi.com/tags/PowerShell/"/>
    
  </entry>
  
  <entry>
    <title>Validating ASP.NET MVC Models with FluentValidation</title>
    <link href="http://devkimchi.com/2015/06/17/validating-asp-net-mvc-models-with-fluent-validation/"/>
    <id>http://devkimchi.com/2015/06/17/validating-asp-net-mvc-models-with-fluent-validation/</id>
    <published>2015-06-17T04:08:52.000Z</published>
    <updated>2016-09-13T12:11:48.453Z</updated>
    
    <content type="html"><![CDATA[<p>While <a href="https://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations(v=vs.110" target="_blank" rel="external">Data Annotations</a>.aspx) approach is generally used for user input data validation, <a href="https://github.com/JeremySkinner/FluentValidation" target="_blank" rel="external">FluentValidation</a> that I’m going to introduce in this article might be better for delelopers with more benefits. Source code used in this post can be found at:</p>
<ul>
<li><a href="https://github.com/devkimchi/FluentValidation-Sample" target="_blank" rel="external">https://github.com/devkimchi/FluentValidation-Sample</a></li>
</ul>
<h2 id="Typical-User-Input-Data-Validation-with-Data-Annotations"><a href="#Typical-User-Input-Data-Validation-with-Data-Annotations" class="headerlink" title="Typical User Input Data Validation with Data Annotations"></a>Typical User Input Data Validation with Data Annotations</h2><p>Generally, for user input validation, data annotations approach like below is used. Each property that needs to be validated is required to have attribute classes:</p>
<pre><code>public class RegisterViewModel
{
  [Required]
  [DataType(DataType.EmailAddress)]
  [Display(Name = &quot;Email&quot;)]
  public string Email { get; set; }

  [Required]
  [StringLength(100, ErrorMessage = &quot;The {0} must be at least {2} characters long.&quot;, MinimumLength = 6)]
  [DataType(DataType.Password)]
  [Display(Name = &quot;Password&quot;)]
  public string Password { get; set; }

  [Compare(&quot;Password&quot;, ErrorMessage = &quot;The password and confirmation password do not match.&quot;)]
  [DataType(DataType.Password)]
  [Display(Name = &quot;Confirm password&quot;)]
  public string ConfirmPassword { get; set; }
}
`&lt;/pre&gt;

Attribute classes like `Required`, `StringLength` and `Compare` are responsible for data validation. If we use them, `ModelState.IsValid` value in the controller can be either `true` (valid) or `false` (invalid).

&lt;pre&gt;`[HttpPost]
public virtual async Task&amp;lt;ActionResult&amp;gt; Register(RegisterViewModel form)
{
  var vm = form;
  if (ModelState.IsValid)
  {
    vm.Validated = true;
  }
  return View(vm);
}
`&lt;/pre&gt;

It&apos;s perfectly OK for data validation. However, personally, this looks too verbose to me. I need a single point for data validation. If you are like me, [`FluentValidation`](https://github.com/JeremySkinner/FluentValidation) will be yours. Let&apos;s change this model using `FluentValidation`

## User Input Data Validation with FluentValidation

You might need to download two packages from [NuGet](https://nuget.org):
</code></pre><ul>
<li><a href="https://www.nuget.org/packages/FluentValidation/" target="_blank" rel="external">FluentValidation</a></li>
<li><p><a href="https://www.nuget.org/packages/FluentValidation.MVC5/" target="_blank" rel="external">FluentValidation.MVC5</a></p>
<p>Once you download both, then the <code>RegisterViewModel</code> class can be changed to:</p>
<pre>`[Validator(typeof(RegisterViewModelValidator))]
public class RegisterViewModel
{
  [Display(Name = "Email")]
  public string Email { get; set; }

  [DataType(DataType.Password)]
  [Display(Name = "Password")]
  public string Password { get; set; }

  [DataType(DataType.Password)]
  [Display(Name = "Confirm password")]
  public string ConfirmPassword { get; set; }
}
`</pre>

<p>As you can see, <code>Validator(typeof(RegisterViewModelValidator))</code> has been added and <code>Required</code>, <code>StringLength</code> and <code>Compare</code> have been removed. Yes, that’s right. <code>RegisterViewModelValidator</code> defines all the validation rules like:</p>
<pre>`public class RegisterViewModelValidator : AbstractValidator&lt;RegisterViewModel&gt;
{
  public RegisterViewModelValidator()
  {
    RuleFor(x =&gt; x.Email)
      .NotNull().WithMessage("Required")
      .EmailAddress().WithMessage("Invalid email");

    RuleFor(x =&gt; x.Password)
      .NotNull().WithMessage("Required")
      .Length(6, 100).WithMessage("Too short or too long");

    RuleFor(x =&gt; x.ConfirmPassword)
      .NotNull().WithMessage("Required")
      .Equal(x =&gt; x.Password).WithMessage("Not matched");
  }
}
`</pre>

<p>Once of benefits using <code>FluentValidation</code> is that setting validation rules looks very intuitive. For example, the <code>Email</code> property is <strong>required</strong> (Not NULL) and <strong>formatted as an email</strong>. In addition to this, each validation rule has its own error message when the validation fails. Once validators are defined, <code>Application_Start()</code> from <code>Global.asax.cs</code> should call <code>FluentValidationModelValidatorProvider.Configure()</code> to activate those validators defined.</p>
<pre>`public class MvcApplication : System.Web.HttpApplication
{
  protected void Application_Start()
  {
    ...

    FluentValidationModelValidatorProvider.Configure();
  }
}
`</pre>

<p>Now, <code>ModelState.IsValid</code> property still has <code>true</code> or <code>false</code> after the validation. Let’s move on to setting up views.</p>
<h2 id="Setting-up-Views-for-User-Input"><a href="#Setting-up-Views-for-User-Input" class="headerlink" title="Setting up Views for User Input"></a>Setting up Views for User Input</h2><p>Corresponding Razore view might look like this:</p>
<p><pre>`@using (Html.BeginForm(MVC.Home.ActionNames.Register, MVC.Home.Name, FormMethod.Post))<br>{<br>  &lt;div&gt;</pre></p>
<pre><code>@Html.LabelFor(m =&amp;gt; m.Email)
&amp;lt;div&amp;gt;
  @Html.TextBoxFor(m =&amp;gt; m.Email, new Dictionary&amp;lt;string, object&amp;gt;() { { &quot;placeholder&quot;, &quot;Email&quot; } })
  @Html.ValidationMessageFor(m =&amp;gt; m.Email)
&amp;lt;/div&amp;gt;
</code></pre><p>  &lt;/div&gt;<br>  &lt;div&gt;</p>
<pre><code>@Html.LabelFor(m =&amp;gt; m.Password)
&amp;lt;div&amp;gt;
  @Html.PasswordFor(m =&amp;gt; m.Password, new Dictionary&amp;lt;string, object&amp;gt;() { { &quot;placeholder&quot;, &quot;Password&quot; } })
  @Html.ValidationMessageFor(m =&amp;gt; m.Password)
&amp;lt;/div&amp;gt;
</code></pre><p>  &lt;/div&gt;<br>  &lt;div&gt;</p>
<pre><code>@Html.LabelFor(m =&amp;gt; m.ConfirmPassword)
&amp;lt;div&amp;gt;
  @Html.PasswordFor(m =&amp;gt; m.ConfirmPassword, new Dictionary&amp;lt;string, object&amp;gt;() { { &quot;placeholder&quot;, &quot;Confirm Password&quot; } })
  @Html.ValidationMessageFor(m =&amp;gt; m.ConfirmPassword)
&amp;lt;/div&amp;gt;
</code></pre><p>  &lt;/div&gt;<br>  &lt;div&gt;</p>
<pre><code>&amp;lt;div&amp;gt;
  &amp;lt;input type=&quot;submit&quot; name=&quot;Submit&quot; /&amp;gt;
&amp;lt;/div&amp;gt;
</code></pre><p>  &lt;/div&gt;<br>}<br>`</p>
<p>This will be rendered in a web browser like:</p>
<pre>`&lt;form action="/Home/Register" method="post"&gt;
  &lt;div&gt;
    &lt;label for="Email"&gt;Email&lt;/label&gt;
    &lt;div&gt;
      &lt;input data-val="true" data-val-email="Invalid email" data-val-required="Required" id="Email" name="Email" placeholder="Email" type="text" value="" /&gt;
      &lt;span class="field-validation-valid" data-valmsg-for="Email" data-valmsg-replace="true"/&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div&gt;
    &lt;label for="Password"&gt;Password&lt;/label&gt;
    &lt;div&gt;
      &lt;input data-val="true" data-val-length="Too short or too long" data-val-length-max="100" data-val-length-min="6" data-val-required="Required" id="Password" name="Password" placeholder="Password" type="password" /&gt;
      &lt;span class="field-validation-valid" data-valmsg-for="Password" data-valmsg-replace="true"/&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div&gt;
    &lt;label for="ConfirmPassword"&gt;Confirm password&lt;/label&gt;
    &lt;div&gt;
      &lt;input data-val="true" data-val-equalto="Not matched" data-val-equalto-other="*.Password" data-val-required="Required" id="ConfirmPassword" name="ConfirmPassword" placeholder="Confirm Password" type="password" /&gt;
      &lt;span class="field-validation-valid" data-valmsg-for="ConfirmPassword" data-valmsg-replace="true"/&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div&gt;
    &lt;div&gt;
      &lt;input type="submit" name="Submit" /&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/form&gt;
`</pre>

<p>Therefore, the controller performs server-side validation. If you add a javascript validation library like <a href="https://www.nuget.org/packages/jQuery.Validation/" target="_blank" rel="external">jQuery Validation</a>, client-side validation can also be easily developed.</p>
<h2 id="Setting-up-IoC-Container-for-Dependency-Injection-for-Validation"><a href="#Setting-up-IoC-Container-for-Dependency-Injection-for-Validation" class="headerlink" title="Setting up IoC Container for Dependency Injection for Validation"></a>Setting up IoC Container for Dependency Injection for Validation</h2><p>Any validator using <code>FluentValidation</code> library inherits <code>AbstractValidator&amp;lt;T&amp;gt;</code> which implements the <code>IValidator</code> interface. It’s great because classes implementing interfaces can easily be both unit-testable and dependency-injectable. Let’s have a look how to setup IoC containers for those validators using <a href="http://autofac.org" target="_blank" rel="external">Autofac</a>. First of all, change <code>Application_Start()</code> from <code>Global.asax.cs</code> like below:</p>
<pre>`private void Application_Start(object sender, EventArgs e)
{
  ...

  DependencyConfig.RegisterDependencies();
}
`</pre>

<p>As you can see, <code>FluentValidationModelValidatorProvider.Configure()</code> within the <code>Application_Start()</code> method has been replaced with <code>DependencyConfig.RegisterDependencies()</code>. <code>DependencyConfig</code> class under the <code>App_Start</code> directory might look like:</p>
<pre>`public static class DependencyConfig
{
  public static void RegisterDependencies()
  {
    var builder = new ContainerBuilder();

    ...

    RegisterValidators(builder);

    var container = builder.Build();

    DependencyResolver.SetResolver(new AutofacDependencyResolver(container));

    RegisterValidationProviders(container);
  }

  private static void RegisterValidators(ContainerBuilder builder)
  {
    builder.RegisterType&lt;RegisterViewModelValidator&gt;()
           .Keyed&lt;IValidator&gt;(typeof(IValidator&lt;RegisterViewModel&gt;))
           .As&lt;IValidator&gt;();
  }

  ...
}
`</pre>

<p>For more details to build dependencies can be found at <code>Autofac</code> website. Instead, we’re focusing on two private methods &ndash; <code>RegisterValidators()</code> and <code>RegisterValidationProviders()</code>. All validator classes should go into the <code>RegisterValidators()</code> method for IoC registration. The <code>RegisterValidationProviders()</code> method actually activates validators implemented by <code>FluentValidation</code> library like:</p>
<pre>`private static void RegisterValidationProviders(IContainer container)
{
  ModelValidatorProviders.Providers.Clear(); #1
  DataAnnotationsModelValidatorProvider.AddImplicitRequiredAttributeForValueTypes = false; #2
  var fvmvp = new FluentValidationModelValidatorProvider(new ValidatorFactory(container))
              {
                AddImplicitRequiredValidator = false,
              }; #3
  ModelValidatorProviders.Providers.Add(fvmvp); #4
}
`</pre>
</li>
<li><p><code>#1</code>: There might be existing validator providers within memory. This clears the memory first.</p>
</li>
<li><code>#2</code>: This explicitly declares to perform <code>DataAnnotations</code> model validation.</li>
<li><code>#3</code>: This creates validators provided by <code>FluentValidation</code> using <code>ValidatorFactory</code> class. This also explicitly declares to perform validations.</li>
<li><p><code>#4</code>: This adds validators using <code>FluentValidation</code> library.</p>
<p>There might be many validator classes inheriting <code>AbstractValidator&amp;lt;T&amp;gt;</code> for each model. Therefore, all registered validators into <code>Autofac</code> should be instantiated by this <code>ValidatorFactory</code> class. Here’s the details:</p>
<pre>`public class ValidatorFactory : ValidatorFactoryBase
{
  private readonly IContainer container;

  public ValidatorFactory(IContainer container)
  {
    this.container = container;
  }

  public override IValidator CreateInstance(Type validatorType)
  {
    var validator = container.ResolveOptionalKeyed&lt;IValidator&gt;(validatorType);
    return validator;
  }
}
`</pre>

<p>As stated above, this is possible because all validators implements <code>IValidator</code> interface. Once we completes this step, we should remove all <code>[Validator(typeof(TValidator))]</code> attribute classes on models. For this case, it will be <code>[Validator(typeof(RegisterViewModelValidator))]</code>.</p>
<h2 id="Unit-Testing-Validators"><a href="#Unit-Testing-Validators" class="headerlink" title="Unit Testing Validators"></a>Unit Testing Validators</h2><p>As <code>IValidator</code> interface gives us much flexibility, we can also perform unit tests. With <a href="http://nunit.org" target="_blank" rel="external">NUnit</a> and <a href="https://github.com/dennisdoomen/fluentassertions" target="_blank" rel="external">FluentAssertions</a>, we can easily write unit tests.</p>
<pre>`[TestFixture]
public class RegisterModelValidatorTest
{
  private IValidator _validator;

  [SetUp]
  public void Init()
  {
    this._validator = new RegisterViewModelValidator();
  }

  [Test]
  [TestCase("email", "password", "password", false)]
  [TestCase(null, "password", "password", false)]
  [TestCase("e@mail.com", "password", "password", true)]
  public void RegisterViewModel_Should_Be_Validated(string email,
                                                    string password,
                                                    string confirmPassword,
                                                    bool expected)
  {
    var vm = new RegisterViewModel()
                 {
                   Email = email,
                   Password = password,
                   ConfirmPassword = confirmPassword,
                 };
    var result = this._validator.Validate(vm);
    result.IsValid.Should().Be(expected);
  }
`</pre>

<p>Any validator implementing the <code>IValidator</code> interface has the <code>Validate()</code> method that actually performs the validation. Like above, the model is validated and tested. However, this conducts validation for whole properties in the model. If I want to test only one property, what can I do? <code>FluentValidation</code> provides a few helper methods for this case.</p>
</li>
<li><p><code>ShouldHaveValidationErrorFor()</code></p>
</li>
<li><code>ShouldNotHaveValidationErrorFor()</code></li>
<li><p><code>ShouldHaveChildValidator()</code></p>
<p>Therefore, testing one property can be written like:</p>
<pre>`[Test]
[TestCase("password", false)]
[TestCase(null, true)]
public void Password_Should_Be_Validated(string password, bool exceptionExpected)
{
  var validator = this._validator as RegisterViewModelValidator;
  try
  {
    validator.ShouldNotHaveValidationErrorFor(p =&gt; p.Password, password);
  }
  catch (ValidationTestException ex)
  {
    if (exceptionExpected)
    {
      Assert.Pass();
    }
    else
    {
      Assert.Fail(ex.Message);
    }
  }
  catch (Exception ex)
  {
    Assert.Fail(ex.Message);
  }
}
`</pre>

<p>The <code>Password</code> property of the <code>RegisterViewModel</code> model has a validation rule in <code>RegisterViewModelValidator</code> class. Hence, it will be tested. The helper method, <code>ShouldNotHaveValidationErrorFor()</code>, will be passed, if the validation succeeds. However, if the validation fails, it will throw the <code>ValidationTestException</code> exception. If this is expected, it passes the test; otherwise it fails the test. Likewise, the <code>ConfirmPassword</code> property can be tested like below:</p>
<p><pre>`[Test]<br>[TestCase(“password”, “password”, false)]<br>[TestCase(“password”, “different”, true)]<br>public void ConfirmPassword_Should_Be_Validated(string password, string confirmPassword, bool exceptionExpected)<br>{<br>  var validator = this._validator as RegisterViewModelValidator;<br>  try<br>  {</pre></p>
<pre><code>validator.ShouldNotHaveValidationErrorFor(
    p =&amp;gt; p.ConfirmPassword,
    new RegisterViewModel() { Password = password, ConfirmPassword = confirmPassword });
</code></pre><p>  }<br>  catch (ValidationTestException ex)<br>  {</p>
<pre><code>if (exceptionExpected)
{
    Assert.Pass();
}
else
{
    Assert.Fail(ex.Message);
}
</code></pre><p>  }<br>  catch (Exception ex)<br>  {</p>
<pre><code>Assert.Fail(ex.Message);
</code></pre><p>  }<br>}</p>
</li>
</ul>
<p>So far, we’ve take a brief look at using <code>FluentValidation</code> library for our ASP.NET MVC web app. Instead of scattering those validation rules all over the places, we can place them into one spot so that we can get benefits, in terms of maintainablilty.</p>
<p>One of downsides using <code>FluentValidation</code> is that it supports Web API with many limitations. Of course, we can validate models through Web API with many walkarounds. I don’t think, however, it’s efficient. According to the good news from the library creator/maintainer, Jeremy Skinner, <a href="https://github.com/JeremySkinner/FluentValidation/issues/80" target="_blank" rel="external">he has been focusing on ASP.NET MVC 6 with new MVC/Web API features</a>. So, we hope the next version of <code>FluentValidation</code> will fully support both MVC and Web API.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;While &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations(v=vs.110&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Da
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="Dependency Injection" scheme="http://devkimchi.com/tags/Dependency-Injection/"/>
    
      <category term="IoC" scheme="http://devkimchi.com/tags/IoC/"/>
    
      <category term="ASP.NET MVC" scheme="http://devkimchi.com/tags/ASP-NET-MVC/"/>
    
      <category term="DataAnnotations" scheme="http://devkimchi.com/tags/DataAnnotations/"/>
    
      <category term="DI" scheme="http://devkimchi.com/tags/DI/"/>
    
      <category term="FluentValidation" scheme="http://devkimchi.com/tags/FluentValidation/"/>
    
      <category term="Inversion of Control" scheme="http://devkimchi.com/tags/Inversion-of-Control/"/>
    
  </entry>
  
  <entry>
    <title>.NET Wrapper for Google&#39;s New reCaptcha API</title>
    <link href="http://devkimchi.com/2015/04/22/dot-net-wrapper-for-googles-new-recaptcha-api/"/>
    <id>http://devkimchi.com/2015/04/22/dot-net-wrapper-for-googles-new-recaptcha-api/</id>
    <published>2015-04-22T12:57:40.000Z</published>
    <updated>2016-09-13T12:11:48.449Z</updated>
    
    <content type="html"><![CDATA[<p>Google announced on their <a href="http://googleonlinesecurity.blogspot.com.au/2014/12/are-you-robot-introducing-no-captcha.html" target="_blank" rel="external">blog</a> that they introduced a new version of <a href="https://google.com/recaptcha" target="_blank" rel="external">reCaptcha</a> API. As it’s fairly new, not many wrapper library has not been developed. Google has only introduced the official wrapper library in <a href="https://github.com/google/recaptcha" target="_blank" rel="external">PHP</a> for the new version. In this post, even though it’s not officially recognised by Google, I’ll introduce a .NET wrapper library for reCaptcha API.</p>
<p><img src="http://blob.devkimchi.com/devkimchiwp/2015/04/reCaptcha-new.gif" alt=""></p>
<h2 id="NuGet-Package"><a href="#NuGet-Package" class="headerlink" title="NuGet Package"></a>NuGet Package</h2><table><br><thead><br><tr><br>  <th align="center">Aliencube.ReCaptcha.NET</th><br>  <th align="center">Aliencube.ReCaptcha.NET.MVC</th><br></tr><br></thead><br><tbody><br><tr><br>  <td align="center"><a href="https://www.nuget.org/packages/Aliencube.ReCaptcha.NET/" target="_blank" rel="external"><img src="https://img.shields.io/nuget/v/Aliencube.ReCaptcha.NET.svg" alt=""></a> <a href="https://www.nuget.org/packages/Aliencube.ReCaptcha.NET/" target="_blank" rel="external"><img src="https://img.shields.io/nuget/dt/Aliencube.ReCaptcha.NET.svg" alt=""></a></td><br>  <td align="center"><a href="https://www.nuget.org/packages/Aliencube.ReCaptcha.NET.MVC/" target="_blank" rel="external"><img src="https://img.shields.io/nuget/v/Aliencube.ReCaptcha.NET.MVC.svg" alt=""></a> <a href="https://www.nuget.org/packages/Aliencube.ReCaptcha.NET.MVC/" target="_blank" rel="external"><img src="https://img.shields.io/nuget/dt/Aliencube.ReCaptcha.NET.MVC.svg" alt=""></a></td><br></tr><br></tbody><br></table>

<p>Its GitHub repository can be found at: <a href="https://github.com/aliencube/ReCaptcha.NET" target="_blank" rel="external">https://github.com/aliencube/ReCaptcha.NET</a> <a href="https://github.com/aliencube/ReCaptcha.NET" target="_blank" rel="external"><img src="https://ci.appveyor.com/api/projects/status/i5ife0np7indhdiu?svg=true" alt="Build status"></a></p>
<h2 id="How-It-Works"><a href="#How-It-Works" class="headerlink" title="How It Works"></a>How It Works</h2><p>This library is very intuitive for use. If you are developing an ASP.NET MVC web app, all you need is download two NuGet packages stated above and use them. Let’s start from the basic usage.</p>
<h3 id="Basic-Usage"><a href="#Basic-Usage" class="headerlink" title="Basic Usage"></a>Basic Usage</h3><p>First of all, we need a controller to handle the reCaptcha input.</p>
<pre><code>[HttpPost]
public virtual async Task&amp;lt;ActionResult&amp;gt; Index(HomeReCaptchaViewModel form)
{
  var vm = form;

  using (var settings = ReCaptchaV2Settings.CreateInstance())
  using (var reCaptcha = new ReCaptchaV2(settings))
  {
    var result = await reCaptcha.SiteVerifyAsync(this.Request.Form, this.Request.ServerVariables);

    vm.Success = result.Success;
    vm.ErrorCodes = result.ErrorCodes;
  }

  return View(vm);
}
`&lt;/pre&gt;

As you can see, `ReCaptchaV2.SiteVerifyAsync()` takes parameters of `Request.Form` and `Request.ServerVariables`. This is all you need to do in controllers. For views, do the following codes:

&lt;pre&gt;`@using (Html.BeginForm(MVC.Home.ActionNames.Basic, MVC.Home.Name, FormMethod.Post))
{
  ...

  @Html.ReCaptcha(new Dictionary&amp;lt;string, object&amp;gt;() { { &quot;class&quot;, &quot;[class names]&quot; }, { &quot;data-sitekey&quot;, Model.SiteKey } })

  ...
}

@section Scripts
{
  @Html.ReCaptchaApiJs(Model.ApiUrl)
}
`&lt;/pre&gt;
</code></pre><ul>
<li><code>@Html.Recaptcha()</code> renders the reCaptcha control.</li>
<li><p><code>@Html.ReCaptchaApiJs()</code> renders JavaScript for the reCaptcha control.</p>
<p>That’s all. Too easy, huh?</p>
<h3 id="Advanced-Usage"><a href="#Advanced-Usage" class="headerlink" title="Advanced Usage"></a>Advanced Usage</h3><p>You might want more control over the automatic rendering. In this case, you can use the <code>RenderParameters</code> class. Properties of the <code>RenderParameters</code> class can be found at: <a href="https://developers.google.com/recaptcha/docs/display#render_param" target="_blank" rel="external">https://developers.google.com/recaptcha/docs/display#render_param</a>.</p>
<p><pre>`@using (Html.BeginForm(MVC.Home.ActionNames.Advanced, MVC.Home.Name, FormMethod.Post))<br>{<br>  …</pre></p>
<p>  @Html.ReCaptcha(new Dictionary&lt;string, object&gt;() { { “class”, “form-group” } }, new RenderParameters() { SiteKey = Model.SiteKey, Theme = RenderThemeType.Dark })</p>
<p>  …<br>}<br>`</p>
<p>Rendering <code>api.js</code> can be asynchronous. For this, you can add the <code>ApiJsRenderingOptions</code> enum like:</p>
<p><pre><code>@section Scripts
{
  @Html.ReCaptchaApiJs(Model.ApiUrl, ApiJsRenderingOptions.Async | ApiJsRenderingOptions.Defer)
}</code></pre></p>
<h3 id="Callback-Usage"><a href="#Callback-Usage" class="headerlink" title="Callback Usage"></a>Callback Usage</h3><p>If you want to control completely by yourself, this callback approach will be suitable for you.</p>
<p><pre>`@section Scripts<br>{<br>  var callback = “onLoadCallback”;<br>  var elementId = “recaptcha”;</pre></p>
<p>  @Html.ReCaptchaApiJs(Model.ApiUrl,</p>
<pre><code>ApiJsRenderingOptions.Async | ApiJsRenderingOptions.Defer,
new ResourceParameters()
{
  OnLoad = callback,
  Render = WidgetRenderType.Explicit,
  LanguageCode = WidgetLanguageCode.Korean
})
</code></pre><p>  @Html.ReCaptchaCallbackJs(callback,</p>
<pre><code>elementId,
new RenderParameters()
{
  SiteKey = Model.SiteKey,
  Theme = RenderThemeType.Dark
})
</code></pre><p>}<br>`</p>
<p>For this, the <code>ResourceParameters</code> class is used in <code>ReCaptchaApiJs()</code>. This enables to load callback function that is loaded by <code>ReCaptchaCallbackJs()</code>. As all rendering options are defined here, the actual HTML part look like:</p>
<p><pre>`@using (Html.BeginForm(MVC.Home.ActionNames.Advanced, MVC.Home.Name, FormMethod.Post))<br>{<br>  …</pre></p>
<p>  &lt;div class=”form-group” id=”@elementId”&gt;&lt;/div&gt;</p>
<p>  …<br>}<br>`</p>
</li>
<li><p><code>@Html.RecaptchaCallbackJs()</code> renders JavaScript callback function for the reCaptcha control.</p>
<h2 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h2><p>As you can see the above example codes, configuration settings needs to be instantiated first by calling:</p>
<pre>`var settings = ConverterSettings.CreateInstance();
`</pre>

<p>Alternatively, the <code>settings</code> instance can be injected by any IoC container. The following code is, for example, using <a href="http://autofac.org" target="_blank" rel="external">Autofac</a></p>
<pre>`var builder = new ContainerBuilder();

...

builder.Register(p =&gt; ReCaptchaV2Settings.CreateInstance()).As&lt;IReCaptchaV2Settings&gt;();
builder.RegisterType&lt;ReCaptchaV2&gt;().As&lt;IReCaptchaV2&gt;();

...

var container = builder.Build();
`</pre>

<p>This <code>settings</code> instance comes from either <code>reCaptchaV2Settings</code> section or <code>appSettings</code> section on <code>App.config</code> or <code>Web.config</code>. It firstly look for the <code>reCaptchaV2Settings</code> section and, if no <code>reCaptchaV2Settings</code> section is found, then look for the <code>appSettings</code> section.</p>
<pre>`&lt;configuration&gt;
  &lt;configSections&gt;
    &lt;section name="reCaptchaV2Settings" type="Aliencube.ReCaptcha.Wrapper.ReCaptchaV2Settings, Aliencube.ReCaptcha.Wrapper" requirePermission="false" /&gt;
  &lt;/configSections&gt;

  &lt;reCaptchaV2Settings
    requestUrl="https://www.google.com/recaptcha/api/siteverify"
    apiUrl="https://www.google.com/recaptcha/api.js"
    siteKey="[YOUR_SITE_KEY]"
    secretKey="[YOUR_SECRET_KEY]" /&gt;
&lt;/configuration&gt;
`</pre>

<p>If you want to simply use the <code>appSettings</code> section, you can do the following instead:</p>
<p><pre>`&lt;configuration&gt;<br>  &lt;appSettings&gt;</pre></p>
<pre><code>&amp;lt;add key=&quot;RequestUrl&quot; value=&quot;https://www.google.com/recaptcha/api/siteverify&quot; /&amp;gt;
&amp;lt;add key=&quot;ApiUrl&quot; value=&quot;https://www.google.com/recaptcha/api.js&quot; /&amp;gt;
&amp;lt;add key=&quot;SiteKey&quot; value=&quot;[YOUR_SITE_KEY]&quot; /&amp;gt;
&amp;lt;add key=&quot;SecretKey&quot; value=&quot;[YOUR_SECRET_KEY]&quot; /&amp;gt;
</code></pre><p>  &lt;/appSettings&gt;<br>&lt;/configuration&gt;</p>
</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>So far, we have reviewed the ReCaptcha.NET library. It’s easy to use and well integrated with ASP.NET MVC apps. With this library, your app will be more secure from spamy bots.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Google announced on their &lt;a href=&quot;http://googleonlinesecurity.blogspot.com.au/2014/12/are-you-robot-introducing-no-captcha.html&quot; target=
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="reCaptcha" scheme="http://devkimchi.com/tags/reCaptcha/"/>
    
      <category term="ReCaptcha.NET" scheme="http://devkimchi.com/tags/ReCaptcha-NET/"/>
    
  </entry>
  
  <entry>
    <title>How to throttle a section in WCF</title>
    <link href="http://devkimchi.com/2015/03/15/how-to-throttle-a-section-in-wcf/"/>
    <id>http://devkimchi.com/2015/03/15/how-to-throttle-a-section-in-wcf/</id>
    <published>2015-03-15T02:33:23.000Z</published>
    <updated>2016-09-13T12:11:48.457Z</updated>
    
    <content type="html"><![CDATA[<p>If a WCF service internally connected to a legacy system which does not support multi threading, the WCF needs to be throttled.</p>
<p>The easiest way to achieve this is to make the WCF works sequentially by setting this up not to work concurrently.</p>
<p>By default, a WCF configured to process in multiple instances and concurrency mode. Before setting up the throttle in WCF, it is important to understand how concurrency works in WCF.</p>
<p>Two columns below are great to understand this.</p>
<p><a href="http://www.codeproject.com/Articles/86007/ways-to-do-WCF-instance-management-Per-call-Per" target="_blank" rel="external">Three ways to do WCF instance management</a><br><a href="http://www.codeproject.com/Articles/89858/WCF-Concurrency-Single-Multiple-and-Reentrant-and" target="_blank" rel="external">WCF Concurrency (Single, Multiple, and Reentrant) and Throttling</a></p>
<p>In a nutshell, it is easy to manage concurrency in WCF. It can be configured in<span id="dbda8d2e-6e81-4e07-83d8-4aa1d02dcd01" class="GINGER_SOFTWARE_mark"><span id="060f4be7-7fd9-4ac5-a467-3722280a54d0" class="GINGER_SOFTWARE_mark"><span id="2e709d0a-ec9d-4410-8a96-cbc9850e9b9b" class="GINGER_SOFTWARE_mark"><span id="2e9f05d0-996c-424d-a5d8-4adc5341cee1" class="GINGER_SOFTWARE_mark"><span id="e4942192-0aa0-4a17-b34a-977f404af4ec" class="GINGER_SOFTWARE_mark">serviceBehaviors</span></span></span></span></span><span id="dbda8d2e-6e81-4e07-83d8-4aa1d02dcd01" class="GINGER_SOFTWARE_mark"><span id="060f4be7-7fd9-4ac5-a467-3722280a54d0" class="GINGER_SOFTWARE_mark"><span id="2e709d0a-ec9d-4410-8a96-cbc9850e9b9b" class="GINGER_SOFTWARE_mark"><span id="2e9f05d0-996c-424d-a5d8-4adc5341cee1" class="GINGER_SOFTWARE_mark"><span id="e4942192-0aa0-4a17-b34a-977f404af4ec" class="GINGER_SOFTWARE_mark"></span></span></span></span></span><span id="dbda8d2e-6e81-4e07-83d8-4aa1d02dcd01" class="GINGER_SOFTWARE_mark"><span id="060f4be7-7fd9-4ac5-a467-3722280a54d0" class="GINGER_SOFTWARE_mark"><span id="2e709d0a-ec9d-4410-8a96-cbc9850e9b9b" class="GINGER_SOFTWARE_mark"><span id="2e9f05d0-996c-424d-a5d8-4adc5341cee1" class="GINGER_SOFTWARE_mark"><span id="e4942192-0aa0-4a17-b34a-977f404af4ec" class="GINGER_SOFTWARE_mark"></span></span></span></span></span><span id="dbda8d2e-6e81-4e07-83d8-4aa1d02dcd01" class="GINGER_SOFTWARE_mark"><span id="060f4be7-7fd9-4ac5-a467-3722280a54d0" class="GINGER_SOFTWARE_mark"><span id="2e709d0a-ec9d-4410-8a96-cbc9850e9b9b" class="GINGER_SOFTWARE_mark"><span id="2e9f05d0-996c-424d-a5d8-4adc5341cee1" class="GINGER_SOFTWARE_mark"><span id="e4942192-0aa0-4a17-b34a-977f404af4ec" class="GINGER_SOFTWARE_mark"></span></span></span></span></span><span id="dbda8d2e-6e81-4e07-83d8-4aa1d02dcd01" class="GINGER_SOFTWARE_mark"><span id="060f4be7-7fd9-4ac5-a467-3722280a54d0" class="GINGER_SOFTWARE_mark"><span id="2e709d0a-ec9d-4410-8a96-cbc9850e9b9b" class="GINGER_SOFTWARE_mark"><span id="2e9f05d0-996c-424d-a5d8-4adc5341cee1" class="GINGER_SOFTWARE_mark"><span id="e4942192-0aa0-4a17-b34a-977f404af4ec" class="GINGER_SOFTWARE_mark"></span></span></span></span></span><span id="dbda8d2e-6e81-4e07-83d8-4aa1d02dcd01" class="GINGER_SOFTWARE_mark"><span id="060f4be7-7fd9-4ac5-a467-3722280a54d0" class="GINGER_SOFTWARE_mark"><span id="2e709d0a-ec9d-4410-8a96-cbc9850e9b9b" class="GINGER_SOFTWARE_mark"><span id="2e9f05d0-996c-424d-a5d8-4adc5341cee1" class="GINGER_SOFTWARE_mark"><span id="e4942192-0aa0-4a17-b34a-977f404af4ec" class="GINGER_SOFTWARE_mark"></span></span></span></span></span><span id="dbda8d2e-6e81-4e07-83d8-4aa1d02dcd01" class="GINGER_SOFTWARE_mark"><span id="060f4be7-7fd9-4ac5-a467-3722280a54d0" class="GINGER_SOFTWARE_mark"><span id="2e709d0a-ec9d-4410-8a96-cbc9850e9b9b" class="GINGER_SOFTWARE_mark"><span id="2e9f05d0-996c-424d-a5d8-4adc5341cee1" class="GINGER_SOFTWARE_mark"><span id="e4942192-0aa0-4a17-b34a-977f404af4ec" class="GINGER_SOFTWARE_mark"></span></span></span></span></span><span id="dbda8d2e-6e81-4e07-83d8-4aa1d02dcd01" class="GINGER_SOFTWARE_mark"><span id="060f4be7-7fd9-4ac5-a467-3722280a54d0" class="GINGER_SOFTWARE_mark"><span id="2e709d0a-ec9d-4410-8a96-cbc9850e9b9b" class="GINGER_SOFTWARE_mark"><span id="2e9f05d0-996c-424d-a5d8-4adc5341cee1" class="GINGER_SOFTWARE_mark"><span id="e4942192-0aa0-4a17-b34a-977f404af4ec" class="GINGER_SOFTWARE_mark"></span></span></span></span></span><span id="dbda8d2e-6e81-4e07-83d8-4aa1d02dcd01" class="GINGER_SOFTWARE_mark"><span id="060f4be7-7fd9-4ac5-a467-3722280a54d0" class="GINGER_SOFTWARE_mark"><span id="2e709d0a-ec9d-4410-8a96-cbc9850e9b9b" class="GINGER_SOFTWARE_mark"><span id="2e9f05d0-996c-424d-a5d8-4adc5341cee1" class="GINGER_SOFTWARE_mark"><span id="e4942192-0aa0-4a17-b34a-977f404af4ec" class="GINGER_SOFTWARE_mark"></span></span></span></span></span> section of web<span id="e7b79c35-e39e-44f1-89bc-831959bf8364" class="GINGER_SOFTWARE_mark"><span id="5fa2bafb-2951-432a-bcac-c73c468c6ded" class="GINGER_SOFTWARE_mark"><span id="3ef30ea8-7132-4d0c-afec-92d66af92e58" class="GINGER_SOFTWARE_mark"><span id="5db5b8f6-c5f7-4a47-97db-87635272377f" class="GINGER_SOFTWARE_mark"><span id="a81c99de-d2cb-4550-8703-b373831047cd" class="GINGER_SOFTWARE_mark">.</span></span></span></span></span><span id="2e0c3aef-63f8-4ba7-9f25-c6eeeedc8f8e" class="GINGER_SOFTWARE_mark"><span id="4a426cde-a4a7-4c6f-ab66-f1f9ad34828b" class="GINGER_SOFTWARE_mark"><span id="0b40d9a0-2c21-4e2d-b6f3-c8b646e35d87" class="GINGER_SOFTWARE_mark"><span id="35856ba8-c1e5-4011-a3e2-9fdc588dfbe5" class="GINGER_SOFTWARE_mark"><span id="f9bf5dd5-bc2c-4bfe-8dc1-19e16e32b455" class="GINGER_SOFTWARE_mark">confing</span></span></span></span></span>.</p>
<pre class="lang:default decode:true ">&lt;serviceBehaviors&gt; 
    &lt;behavior name="serviceBehavior"&gt; 
        &lt;serviceThrottling 
           maxConcurrentCalls="16"
           maxConcurrentSessions="10"
           maxConcurrentInstances="2147483647" 
        /&gt; 
    &lt;/behavior&gt; 
&lt;/serviceBehaviors&gt;</pre>

<p>&nbsp;</p>
<p>In my case, I needed to make this WCF accept the client <span id="63c1ceac-3085-45fe-b67c-16f645346104" class="GINGER_SOFTWARE_mark"><span id="bc30e313-ad3b-4292-89f5-8eab1f641a0d" class="GINGER_SOFTWARE_mark"><span id="639267cd-af55-417c-ae01-51917708ec6d" class="GINGER_SOFTWARE_mark"><span id="19b45173-d535-486e-b6cd-03b29d9ce6e1" class="GINGER_SOFTWARE_mark"><span id="eab44f09-4bb9-440b-b32c-6b0effdf11f5" class="GINGER_SOFTWARE_mark">request as</span></span></span></span></span> fast as it can, but had to call the back-end process in a given interval.</p>
<p>To accomplish this, I changed <span id="cfa61294-06ef-42d4-8577-15d8f9f0091e" class="GINGER_SOFTWARE_mark"><span id="cce7c3d9-5665-4ff0-b526-3e3ba2dd36e9" class="GINGER_SOFTWARE_mark"><span id="e3a92720-279f-451c-9cde-835c3d5abe2d" class="GINGER_SOFTWARE_mark"><span id="2c6f8a20-2f1f-4833-ac90-d22a9bb5cf74" class="GINGER_SOFTWARE_mark"><span id="6bc4418c-7453-42ce-b0ee-55af0f4f4d8f" class="GINGER_SOFTWARE_mark">the configuration</span></span></span></span></span> as below.</p>
<pre class="lang:default decode:true ">&lt;serviceBehaviors&gt; 
    &lt;behavior name="serviceBehavior"&gt; 
        &lt;serviceThrottling maxConcurrentInstances="1" /&gt; 
    &lt;/behavior&gt; 
&lt;/serviceBehaviors&gt;</pre>

<p>&nbsp;</p>
<p>This configuration means the WCF will have only a single instance. However, by default, this WCF can have multiple threads working <span id="ae628db1-06fe-449a-b595-63feb76f12a2" class="GINGER_SOFTWARE_mark">on</span> <span id="a4c47282-1213-4455-939f-0af31eec6898" class="GINGER_SOFTWARE_mark">concurrency</span>.</p>
<p>The basic idea to throttle is having a static variable that can work as a gate keeper.</p>
<pre class="lang:default decode:true ">public class Throttle:  IThrottle
{
    public static DateTime staticTime;

    DoWork()
    {
        // do something
    }    

    while (true)
    {
        if (DateTime.Now - westpaccws.staticTime &gt; TimeSpan.FromMilliseconds(300))
        {
            westpaccws.staticTime = DateTime.Now;
            break;
        }
    }

    DoThrottledWork()
    {
        // do something else that needs to be throttled.
    }
}</pre>

<p>&nbsp;</p>
<p>In this example, the static <span id="b8405516-ef23-483a-9305-9384169b68a3" class="GINGER_SOFTWARE_mark"><span id="27b36a41-f23b-4324-bd46-b5b4250780ca" class="GINGER_SOFTWARE_mark"><span id="d714a23f-878d-4b15-9b1a-0457d90f78eb" class="GINGER_SOFTWARE_mark"><span id="b95e494c-f6db-46a7-b913-fd426c9ec957" class="GINGER_SOFTWARE_mark"><span id="062ce47e-8bd0-4ab3-a3cc-d4fd25c401f0" class="GINGER_SOFTWARE_mark">varialbe</span></span></span></span></span> ‘<span id="a68eb5eb-013b-4052-ae31-8f9b7b9dfad9" class="GINGER_SOFTWARE_mark"><span id="3ba02119-2209-4693-b0db-e400fcd8fab4" class="GINGER_SOFTWARE_mark"><span id="b87a9017-ec7c-422e-98a6-d9d4c705b26f" class="GINGER_SOFTWARE_mark"><span id="9d717113-70d8-4d01-815c-c0df8be6b0ed" class="GINGER_SOFTWARE_mark"><span id="023eff35-033f-4c59-a8a6-50c6a25c10f3" class="GINGER_SOFTWARE_mark">staticTime’</span></span></span></span></span> is shared by all threads. Only after 0.3 seconds has passed, a thread can proceed to the next step. The static variable must be defined in the main class of the service. Otherwise, the static variable will not work as we expected.</p>
<p>This looked like working at first. But, not really. In some cases, multiple threads accessed the <span id="40efbd1a-72bc-4b6f-a0d5-e4f8f426bba2" class="GINGER_SOFTWARE_mark"><span id="6fb280c5-eb82-4675-a2a8-76d892b470fc" class="GINGER_SOFTWARE_mark"><span id="5d02ddd9-964e-4a7e-8834-1a27536850ff" class="GINGER_SOFTWARE_mark"><span id="beb127e5-e5b5-4666-9d0d-fceb47c115ed" class="GINGER_SOFTWARE_mark"><span id="3bb4e893-dacc-47cc-bf32-108eaa7ce334" class="GINGER_SOFTWARE_mark">staticTime</span></span></span></span></span> at the same time and each one decided that it’s good to go.</p>
<p>So, I had to add <span id="db9029d8-74a4-4e68-b033-4bb86dedb863" class="GINGER_SOFTWARE_mark"><span id="07e09d7d-12c4-488a-b272-554684b8cec4" class="GINGER_SOFTWARE_mark"><span id="b3db05a6-fb4b-42d7-8e71-85b00885092f" class="GINGER_SOFTWARE_mark"><span id="02ac0705-0d10-46ce-aaf9-ff0d30c83aed" class="GINGER_SOFTWARE_mark"><span id="c056e80e-aaf8-4d11-9649-c72bff3c7fda" class="GINGER_SOFTWARE_mark">lock</span></span></span></span></span> around time checking routine.</p>
<pre class="lang:default decode:true">public class Throttle:  IThrottle
{
    public static DateTime staticTime;
    public static Object lockthis = new object();

    DoWork()
    {
        // do something
    }    

    while (true)
    {
        lock (lockthis)
        {
            if (DateTime.Now - westpaccws.staticTime &gt; TimeSpan.FromMilliseconds(300))
            {
                westpaccws.staticTime = DateTime.Now;
                break;
            }
        }
    }

    DoThrottledWork()
    {
        // do something else that needs to be throttled.
    }
}</pre>

<p>&nbsp;</p>
<div class="code-embed-wrapper"><br><div class="code-embed-infos">This works well for me as I have only one WCF installed in the server.</div><br></div>

<p>If this will be put on the load balanced environment, the static variable may need to be changed to something else, such as a separate windows service.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;If a WCF service internally connected to a legacy system which does not support multi threading, the WCF needs to be throttled.&lt;/p&gt;
&lt;p&gt;Th
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="concourrency" scheme="http://devkimchi.com/tags/concourrency/"/>
    
      <category term="WCF" scheme="http://devkimchi.com/tags/WCF/"/>
    
  </entry>
  
  <entry>
    <title>Can JSON Web Token (JWT) Be an Alternative for Session?</title>
    <link href="http://devkimchi.com/2015/03/04/can-json-web-token-jwt-be-an-alternative-for-session/"/>
    <id>http://devkimchi.com/2015/03/04/can-json-web-token-jwt-be-an-alternative-for-session/</id>
    <published>2015-03-04T03:30:52.000Z</published>
    <updated>2016-09-13T12:11:48.448Z</updated>
    
    <content type="html"><![CDATA[<p>JSON Web Token (JWT) is nowadays commonly used for authentication, which is driven by IEFT OAuth Working Group. The current version of its <a href="https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32" target="_blank" rel="external">draft</a> is 32. Unlike other authentication tokens, JWT is a JSON object basically and encrypted as a string with delimiters.</p>
<p>JWT has been widely adapted for apps to send/receive RESTful API calls to web servers. For web applications, session objects are commonly used for authentication. Then, why not JWT? One of benefits using JWT as an authentication method, JWT is not server dependent, while session objects are. That means, if we use session objects for authentication, it will be quite tricky to handle between load-balanced web servers. JWT doesn’t necessarily rely on servers, on the other hand.</p>
<p>Here’s a sample code repository for JWT authentication with ASP.NET MVC.</p>
<ul>
<li><a href="https://github.com/devkimchi/JWT-Authentication" target="_blank" rel="external">https://github.com/devkimchi/JWT-Authentication</a></li>
</ul>
<h2 id="Creating-JWT"><a href="#Creating-JWT" class="headerlink" title="Creating JWT"></a>Creating JWT</h2><p>This requires JWT package, <a href="http://www.nuget.org/packages/System.IdentityModel.Tokens.Jwt" target="_blank" rel="external">http://www.nuget.org/packages/System.IdentityModel.Tokens.Jwt</a>, from NuGet.</p>
<pre><code>var now = DateTime.UtcNow;
var tokenHandler = new JwtSecurityTokenHandler();
var symmetricKey = GetBytes(&quot;ThisIsAnImportantStringAndIHaveNoIdeaIfThisIsVerySecureOrNot!&quot;);
var tokenDescriptor = new SecurityTokenDescriptor
                          {
                            Subject = new ClaimsIdentity(new Claim[]
                                                             {
                                                               new Claim(ClaimTypes.Name, &quot;DevKimchi&quot;),
                                                               new Claim(ClaimTypes.Role, &quot;User&quot;),
                                                             }),
                            TokenIssuerName = &quot;http://devkimchi.com&quot;,
                            AppliesToAddress = &quot;http://jwt-sample.com&quot;,
                            Lifetime = new Lifetime(now, now.AddMinutes(30)),
                            SigningCredentials = new SigningCredentials(new InMemorySymmetricSecurityKey(symmetricKey),
                                                                        &quot;http://www.w3.org/2001/04/xmldsig-more#hmac-sha256&quot;,
                                                                        &quot;http://www.w3.org/2001/04/xmlenc#sha256&quot;),
                          };
var token = tokenHandler.CreateToken(tokenDescriptor);
var tokenString = tokenHandler.WriteToken(token);

var cookie = new HttpCookie(&quot;.JWTAUTH&quot;, tokenString) { HttpOnly = true, };
`&lt;/pre&gt;
</code></pre><ul>
<li><code>symmetricKey</code>: To encrypt authentication details.</li>
<li><code>tokenDescriptor</code>: To create JSON token meeting all the requirements set by IETF. Basically, it contains login details, token issuing erver, token consuming location, token validation period and token encryption method. With these details, JWT is tokenised (<code>token</code>) and encrypted (<code>tokenString</code>).</li>
<li><p><code>cookie</code>: To store the encrypted token.</p>
<h2 id="Additional-Encryption-with-FormsAuthentication"><a href="#Additional-Encryption-with-FormsAuthentication" class="headerlink" title="Additional Encryption with FormsAuthentication"></a>Additional Encryption with <code>FormsAuthentication</code></h2><blockquote>
<p>It is not necessary but to get more benefit from the <code>FormsAuthentication</code> object.</p>
</blockquote>
<p>ASP.NET MVC web apps use <code>FormsAuthentication</code> object to store auth details into a cookie. The cookie itself has already been encrypted and, when necessary, it’s decrypted at the server side. If we want to use this, the <code>tokenString</code> we created above can be stored into the cookie with following:</p>
<pre>`var ticket = new FormsAuthenticationTicket(
                 1,
                 model.Email,
                 now,
                 now.AddMinutes(30),
                 model.RememberMe,
                 tokenString,
                 FormsAuthentication.FormsCookiePath);

var encryptedTicket = FormsAuthentication.Encrypt(ticket);
var cookie = new HttpCookie(FormsAuthentication.FormsCookieName, encryptedTicket) { HttpOnly = true, };
`</pre>
</li>
<li><p><code>ticket</code>: To create a ticket for <code>FormsAuthentication</code>. This ticket is encrypted and stored into <code>encryptedTicket</code>.</p>
</li>
<li><p><code>cooke</code>: To store the encrypted ticket.</p>
<blockquote>
<p>Make sure that, <code>FormsAuthentication</code> object uses the machine key that is unique on each server. Therefore, if you want to use this approach between load-balanced servers, the machine key accross the all servers must be the same as each other.</p>
</blockquote>
<h2 id="Authentication-Verification-at-Global-asax"><a href="#Authentication-Verification-at-Global-asax" class="headerlink" title="Authentication Verification at Global.asax"></a>Authentication Verification at <code>Global.asax</code></h2><p>When you see the ASP.NET <a href="https://msdn.microsoft.com/en-us/library/System.Web.HttpApplication(v=vs.110" target="_blank" rel="external">HttpApplication lifecycle pipelines</a>.aspx#remarksToggle), in <code>global.asax</code>, <code>AuthenticationRequest</code> can deal with the authentication check using the event handler, <code>Application_AuthenticationRequest</code>.</p>
<pre>`var jwtCookie = Request.Cookies[".JWTAUTH"];
var userData = jwtCookie.Value;

var tokenHandler = new JwtSecurityTokenHandler();
var symmetricKey = GetBytes("ThisIsAnImportantStringAndIHaveNoIdeaIfThisIsVerySecureOrNot!");
var validationParameters = new TokenValidationParameters()
                           {
                             ValidAudience = "http://jwt-sample.com",
                             ValidIssuer = "http://devkimchi.com",
                             IssuerSigningToken = new BinarySecretSecurityToken(symmetricKey)
                           };
SecurityToken securityToken;
var principal = tokenHandler.ValidateToken(userData, validationParameters, out securityToken);

Context.User = principal;
`</pre>
</li>
<li><p><code>symmetricKey</code>: To decrypt auth details from JWT. This is the same key above.</p>
</li>
<li><code>validationParameters</code>: To store keys and values to verify JWT. <code>ValidAudience</code>, <code>ValidIssuer</code> and <code>IssuerSigningToken</code> must be valid to be authenticated.</li>
<li><p><code>principal</code>: To store user auth details from JWT.</p>
<p>If <code>FormsAuthentication</code> object was used, we need to do something more beforehand:</p>
<p><pre>`var authCookie = Request.Cookies[FormsAuthentication.FormsCookieName];<br>var authTicket = FormsAuthentication.Decrypt(authCookie.Value);<br>var userData = authTicket.UserData;</pre></p>
</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>So far, we have a brief look at JWT for authentication. It doesn’t seem to be tricky but easy to setup. In addition to this, from the security perspective, authentication can be easily substitute sessions. Especially, one authentication approach can be used for all apps including web apps, desktop apps and mobile apps at one single endpoint. If your system needs to provide an integrated way of authentication, this could be an option.</p>
<blockquote>
<p>Of course, DO NOT use this approach for authorisation. It should be considered separately.</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;JSON Web Token (JWT) is nowadays commonly used for authentication, which is driven by IEFT OAuth Working Group. The current version of it
    
    </summary>
    
      <category term="Uncategorized" scheme="http://devkimchi.com/categories/Uncategorized/"/>
    
    
      <category term="Authentication" scheme="http://devkimchi.com/tags/Authentication/"/>
    
      <category term="JSON Web Token" scheme="http://devkimchi.com/tags/JSON-Web-Token/"/>
    
      <category term="JWT" scheme="http://devkimchi.com/tags/JWT/"/>
    
      <category term="Session" scheme="http://devkimchi.com/tags/Session/"/>
    
  </entry>
  
</feed>
